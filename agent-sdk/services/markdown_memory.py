"""
Markdown æ–‡ä»¶è®°å¿†ç³»ç»Ÿ - Markdown File Memory System

å‚è€ƒ OpenClaw çš„ file-first è®¾è®¡ç†å¿µï¼Œå°†è®°å¿†å­˜å‚¨åœ¨ Markdown æ–‡ä»¶ä¸­ã€‚

ç‰¹æ€§:
  - äººç±»å¯è¯»çš„ Markdown æ ¼å¼
  - Git å‹å¥½ï¼ˆå¯ç‰ˆæœ¬æ§åˆ¶ï¼‰
  - è‡ªåŠ¨æ—¶é—´æˆ³
  - æ—¥å¿—åˆ†å‰²ï¼ˆæ¯æ—¥ä¸€ä¸ªæ–‡ä»¶ï¼‰
  - æ”¯æŒå…ƒæ•°æ®å’Œæ ‡ç­¾
"""

from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional
import re
import logging
import json
import shutil

logger = logging.getLogger(__name__)


class MarkdownMemory:
    """
    Markdown è®°å¿†ç®¡ç†å™¨

    æ–‡ä»¶ç»“æ„:
        ~/.cks-lite/workspace/
        â”œâ”€â”€ MEMORY.md                 # é•¿æœŸè®°å¿†ä¸»æ–‡ä»¶
        â””â”€â”€ memory/
            â”œâ”€â”€ 2026-02-05.md        # ä»Šæ—¥æ—¥å¿—
            â”œâ”€â”€ 2026-02-04.md        # æ˜¨æ—¥æ—¥å¿—
            â””â”€â”€ ...
    """

    def __init__(self, workspace_dir: Path):
        """
        åˆå§‹åŒ– Markdown è®°å¿†ç³»ç»Ÿ

        Args:
            workspace_dir: å·¥ä½œåŒºç›®å½•è·¯å¾„
        """
        self.workspace_dir = Path(workspace_dir)
        self.memory_file = self.workspace_dir / "MEMORY.md"
        self.daily_dir = self.workspace_dir / "memory"
        self.archive_dir = self.daily_dir / "archive"

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.workspace_dir.mkdir(parents=True, exist_ok=True)
        self.daily_dir.mkdir(parents=True, exist_ok=True)
        self.archive_dir.mkdir(parents=True, exist_ok=True)

        # ç¡®ä¿ MEMORY.md å­˜åœ¨
        if not self.memory_file.exists():
            self._initialize_memory_file()

        logger.info(f"Markdown è®°å¿†ç³»ç»Ÿåˆå§‹åŒ–: {self.workspace_dir}")

    def _initialize_memory_file(self):
        """åˆå§‹åŒ– MEMORY.md ä¸»æ–‡ä»¶"""
        content = """# CKS Lite - é•¿æœŸè®°å¿†åº“

> è¿™æ˜¯ AI åŠ©æ‰‹çš„é•¿æœŸè®°å¿†å­˜å‚¨ï¼Œè®°å½•é‡è¦çš„ç”¨æˆ·åå¥½ã€çŸ¥è¯†å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

## ğŸ“ è®°å¿†ç´¢å¼•

### ç”¨æˆ·åå¥½ (Preferences)
- [æš‚æ— è®°å¿†]

### æŠ€æœ¯çŸ¥è¯† (Knowledge)
- [æš‚æ— è®°å¿†]

### ä¸Šä¸‹æ–‡ä¿¡æ¯ (Context)
- [æš‚æ— è®°å¿†]

---

## ğŸ“š è¯¦ç»†è®°å¿†

"""
        self.memory_file.write_text(content, encoding="utf-8")
        logger.info(f"åˆ›å»º MEMORY.md: {self.memory_file}")

    def save_memory(
        self,
        content: str,
        memory_type: str = "knowledge",
        tags: Optional[List[str]] = None
    ) -> str:
        """
        ä¿å­˜è®°å¿†åˆ° MEMORY.md

        Args:
            content: è®°å¿†å†…å®¹
            memory_type: è®°å¿†ç±»å‹ (preference, knowledge, context)
            tags: æ ‡ç­¾åˆ—è¡¨

        Returns:
            è®°å¿† ID
        """
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        memory_id = f"mem_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        # æ„å»ºè®°å¿†æ¡ç›®
        entry = f"\n### [{memory_type}] {memory_id}\n\n"
        entry += f"**æ—¶é—´**: {timestamp}\n\n"

        if tags:
            entry += f"**æ ‡ç­¾**: {', '.join(f'`{tag}`' for tag in tags)}\n\n"

        entry += f"{content}\n\n"
        entry += "---\n"

        # è¿½åŠ åˆ°æ–‡ä»¶æœ«å°¾
        with self.memory_file.open("a", encoding="utf-8") as f:
            f.write(entry)

        logger.info(f"ä¿å­˜è®°å¿†: {memory_id} ({memory_type})")
        return memory_id

    def save_daily_log(self, content: str, log_type: str = "conversation") -> str:
        """
        ä¿å­˜æ—¥å¿—åˆ°æ¯æ—¥æ–‡ä»¶

        Args:
            content: æ—¥å¿—å†…å®¹
            log_type: æ—¥å¿—ç±»å‹ (conversation, system, error)

        Returns:
            æ—¥å¿—æ–‡ä»¶è·¯å¾„
        """
        # ä»Šæ—¥æ—¥å¿—æ–‡ä»¶
        today = datetime.now().strftime("%Y-%m-%d")
        daily_file = self.daily_dir / f"{today}.md"

        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºå¤´éƒ¨
        if not daily_file.exists():
            header = f"# CKS Lite - Daily Log\n\n**æ—¥æœŸ**: {today}\n\n---\n\n"
            daily_file.write_text(header, encoding="utf-8")

        # æ„å»ºæ—¥å¿—æ¡ç›®
        timestamp = datetime.now().strftime("%H:%M:%S")
        entry = f"\n## [{timestamp}] {log_type}\n\n"
        entry += f"{content}\n\n"
        entry += "---\n"

        # è¿½åŠ åˆ°æ–‡ä»¶æœ«å°¾
        with daily_file.open("a", encoding="utf-8") as f:
            f.write(entry)

        logger.info(f"ä¿å­˜æ—¥å¿—: {daily_file.name}")
        return str(daily_file)

    def read_memory(self) -> str:
        """
        è¯»å–å®Œæ•´çš„ MEMORY.md å†…å®¹

        Returns:
            æ–‡ä»¶å†…å®¹
        """
        if not self.memory_file.exists():
            return ""

        return self.memory_file.read_text(encoding="utf-8")

    def read_daily_log(self, date: Optional[str] = None) -> str:
        """
        è¯»å–æŒ‡å®šæ—¥æœŸçš„æ—¥å¿—

        Args:
            date: æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)ï¼Œé»˜è®¤ä»Šå¤©

        Returns:
            æ—¥å¿—å†…å®¹
        """
        if date is None:
            date = datetime.now().strftime("%Y-%m-%d")

        daily_file = self.daily_dir / f"{date}.md"

        if not daily_file.exists():
            return f"# æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {date}"

        return daily_file.read_text(encoding="utf-8")

    def parse_memories(self, content: Optional[str] = None) -> List[Dict]:
        """
        è§£æ MEMORY.md ä¸ºç»“æ„åŒ–æ•°æ®

        Args:
            content: Markdown å†…å®¹ï¼ˆå¯é€‰ï¼Œé»˜è®¤è¯»å– MEMORY.mdï¼‰

        Returns:
            è®°å¿†åˆ—è¡¨
        """
        if content is None:
            content = self.read_memory()

        memories = []

        # æ­£åˆ™åŒ¹é…è®°å¿†æ¡ç›®
        # æ ¼å¼: ### [memory_type] memory_id
        pattern = r"###\s+\[(\w+)\]\s+(mem_[\w]+)\n\n\*\*æ—¶é—´\*\*:\s+([^\n]+)"

        matches = re.finditer(pattern, content)

        for match in matches:
            memory_type = match.group(1)
            memory_id = match.group(2)
            timestamp = match.group(3)

            # æå–å†…å®¹ï¼ˆä¸‹ä¸€ä¸ªä¸‰çº§æ ‡é¢˜æˆ– --- ä¹‹å‰ï¼‰
            start = match.end()
            end_match = re.search(r"\n(###|---)", content[start:])
            if end_match:
                end = start + end_match.start()
            else:
                end = len(content)

            memory_content = content[start:end].strip()

            # æå–æ ‡ç­¾
            tags_match = re.search(r"\*\*æ ‡ç­¾\*\*:\s+([^\n]+)", memory_content)
            tags = []
            if tags_match:
                tag_str = tags_match.group(1)
                tags = [t.strip("`") for t in tag_str.split(",")]
                tags = [t.strip() for t in tags]

            # ç§»é™¤å…ƒæ•°æ®ï¼Œåªä¿ç•™æ­£æ–‡
            memory_text = re.sub(r"\*\*æ—¶é—´\*\*:[^\n]+\n+", "", memory_content)
            memory_text = re.sub(r"\*\*æ ‡ç­¾\*\*:[^\n]+\n+", "", memory_text)
            memory_text = memory_text.strip()

            memories.append({
                "id": memory_id,
                "type": memory_type,
                "timestamp": timestamp,
                "content": memory_text,
                "tags": tags
            })

        logger.info(f"è§£æè®°å¿†: {len(memories)} æ¡")
        return memories

    def search_memories(
        self,
        query: str,
        memory_type: Optional[str] = None
    ) -> List[Dict]:
        """
        ç®€å•æ–‡æœ¬æœç´¢è®°å¿†

        Args:
            query: æœç´¢å…³é”®è¯
            memory_type: è®°å¿†ç±»å‹è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰

        Returns:
            åŒ¹é…çš„è®°å¿†åˆ—è¡¨
        """
        memories = self.parse_memories()

        # å…³é”®è¯åŒ¹é…ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
        query_lower = query.lower()
        results = []

        for memory in memories:
            # ç±»å‹è¿‡æ»¤
            if memory_type and memory["type"] != memory_type:
                continue

            # å†…å®¹åŒ¹é…
            if query_lower in memory["content"].lower():
                results.append(memory)

        logger.info(f"æœç´¢è®°å¿†: query='{query}', æ‰¾åˆ° {len(results)} æ¡")
        return results

    def get_recent_logs(self, days: int = 7) -> List[Dict]:
        """
        è·å–æœ€è¿‘ N å¤©çš„æ—¥å¿—æ–‡ä»¶åˆ—è¡¨

        Args:
            days: å¤©æ•°

        Returns:
            æ—¥å¿—æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨ [{ 'date', 'path', 'size' }, ...]
        """
        from datetime import timedelta

        logs = []
        today = datetime.now()

        for i in range(days):
            date = today - timedelta(days=i)
            date_str = date.strftime("%Y-%m-%d")
            daily_file = self.daily_dir / f"{date_str}.md"

            if daily_file.exists():
                logs.append({
                    "date": date_str,
                    "path": str(daily_file),
                    "size": daily_file.stat().st_size
                })

        logger.info(f"è·å–æœ€è¿‘ {days} å¤©æ—¥å¿—: {len(logs)} ä¸ªæ–‡ä»¶")
        return logs

    def compress_logs(self, days: int = 30):
        """
        å‹ç¼©æ—§æ—¥å¿—ï¼ˆè¶…è¿‡æŒ‡å®šå¤©æ•°çš„ï¼‰

        Args:
            days: ä¿ç•™å¤©æ•°
        """
        from datetime import timedelta

        cutoff_date = datetime.now() - timedelta(days=days)

        # æŸ¥æ‰¾æ‰€æœ‰æ—§æ—¥å¿—æ–‡ä»¶
        old_logs = []
        for log_file in self.daily_dir.glob("*.md"):
            try:
                # ä»æ–‡ä»¶åæå–æ—¥æœŸ
                file_date_str = log_file.stem  # 2026-02-05
                file_date = datetime.strptime(file_date_str, "%Y-%m-%d")

                if file_date < cutoff_date:
                    old_logs.append(log_file)
            except ValueError:
                # æ–‡ä»¶åä¸ç¬¦åˆæ—¥æœŸæ ¼å¼ï¼Œè·³è¿‡
                continue

        moved_logs: List[Dict] = []
        for log_file in sorted(old_logs):
            try:
                file_date = datetime.strptime(log_file.stem, "%Y-%m-%d")
                month_bucket = file_date.strftime("%Y-%m")
            except ValueError:
                month_bucket = "unknown"

            target_dir = self.archive_dir / month_bucket
            target_dir.mkdir(parents=True, exist_ok=True)

            target_path = target_dir / log_file.name
            if target_path.exists():
                # é¿å…è¦†ç›–åŒåæ–‡ä»¶
                target_path = target_dir / f"{log_file.stem}_{int(datetime.now().timestamp())}.md"

            size = 0
            try:
                size = log_file.stat().st_size
            except Exception:
                pass

            shutil.move(str(log_file), str(target_path))
            moved_logs.append(
                {
                    "date": log_file.stem,
                    "from": str(log_file),
                    "to": str(target_path),
                    "size": size,
                }
            )

        if moved_logs:
            index_file = self.archive_dir / "index.jsonl"
            with index_file.open("a", encoding="utf-8") as f:
                for item in moved_logs:
                    record = {"archived_at": datetime.now().isoformat(), **item}
                    f.write(json.dumps(record, ensure_ascii=False) + "\n")

        logger.info(f"å‹ç¼©æ—¥å¿—: æ‰¾åˆ° {len(old_logs)} ä¸ªæ—§æ–‡ä»¶, å·²å½’æ¡£ {len(moved_logs)} ä¸ª")
        return moved_logs

    def export_to_json(self) -> Dict:
        """
        å¯¼å‡ºæ‰€æœ‰è®°å¿†ä¸º JSON æ ¼å¼

        Returns:
            JSON æ ¼å¼çš„è®°å¿†æ•°æ®
        """
        memories = self.parse_memories()
        recent_logs = self.get_recent_logs(days=30)

        return {
            "version": "1.0",
            "export_time": datetime.now().isoformat(),
            "memories": memories,
            "recent_logs": recent_logs
        }

    def import_from_json(self, data: Dict):
        """
        ä» JSON å¯¼å…¥è®°å¿†

        Args:
            data: JSON æ•°æ®
        """
        memories = data.get("memories", [])

        for memory in memories:
            self.save_memory(
                content=memory["content"],
                memory_type=memory["type"],
                tags=memory.get("tags", [])
            )

        logger.info(f"å¯¼å…¥è®°å¿†: {len(memories)} æ¡")


# Utility Functions

def trigger_memory_flush(context: str, threshold: int = 150000) -> bool:
    """
    è§¦å‘è®°å¿†åˆ·æ–°æ£€æŸ¥

    å½“å¯¹è¯ token æ•°æ¥è¿‘é™åˆ¶æ—¶ï¼Œè§¦å‘ AI ä¿å­˜é‡è¦ä¿¡æ¯åˆ° Markdown

    Args:
        context: å½“å‰ä¸Šä¸‹æ–‡ï¼ˆç”¨äºä¼°ç®— token æ•°ï¼‰
        threshold: token é˜ˆå€¼

    Returns:
        æ˜¯å¦éœ€è¦åˆ·æ–°
    """
    # ç®€å•ä¼°ç®—: 1 token â‰ˆ 0.75 è‹±æ–‡å­—ç¬¦
    estimated_tokens = len(context) / 0.75

    if estimated_tokens > threshold:
        logger.warning(f"Token æ•°æ¥è¿‘é™åˆ¶: {estimated_tokens:.0f} / {threshold}")
        return True

    return False


def format_memory_prompt(memories: List[Dict]) -> str:
    """
    æ ¼å¼åŒ–è®°å¿†ä¸ºæç¤ºè¯

    Args:
        memories: è®°å¿†åˆ—è¡¨

    Returns:
        æ ¼å¼åŒ–çš„æç¤ºè¯
    """
    if not memories:
        return "æ²¡æœ‰ç›¸å…³è®°å¿†ã€‚"

    prompt = "ç›¸å…³è®°å¿†:\n\n"

    for i, memory in enumerate(memories, 1):
        prompt += f"{i}. [{memory['type']}] {memory['content'][:100]}...\n"

    return prompt
