"""
CKS Lite Agent SDK - Main Entry Point
åŸºäº Claude Agent SDK çš„æ™ºèƒ½ä»£ç†æœåŠ¡
"""

import os
import sys
import re
import json
import time
import asyncio
import httpx
from pathlib import Path
from datetime import datetime
from uuid import uuid4
from dotenv import load_dotenv
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
import uvicorn
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from core.agent import ClaudeAgent, _desktop_results
from core.memory import MemoryManager
from core.skills_loader import SkillsLoader
from core.skill_installer import SkillInstaller
from core.web_search import WebSearchService
from core.goal_manager import GoalManager
from core.execution_approval import ExecutionApprovalStore
from core.channel_task_queue import ChannelTaskQueue
from core.node_registry import NodeRegistry
from core.autonomy_state import AutonomyStateStore
from services.feishu_adapter import FeishuAdapter
from models.request import (
    ChatRequest,
    MemoryRequest,
    SkillInstallRequest,
    SkillLocalInstallRequest,
    SkillCreateRequest,
    SkillExecuteRequest,
    MCPExecuteRequest,
    GoalKPIRequest,
    GoalOKRRequest,
    GoalProjectRequest,
    GoalTaskRequest,
    GoalDemoBootstrapRequest,
    GoalTaskReviewRequest,
    GoalTaskExecutionPhaseRequest,
    GoalTaskExecutionResumeRequest,
    GoalTaskAgentProfileUpsertRequest,
    GoalDashboardNextTaskRequest,
    GoalSupervisorDispatchRequest,
    GoalSupervisorReviewRequest,
    GoalTaskHandoffClaimRequest,
    GoalTaskSubagentSpawnRequest,
    GoalTaskSubagentControlRequest,
    AiEmployeeUpsertRequest,
    AiEmployeeDeleteRequest,
    AiSkillPresetUpsertRequest,
    AiSkillPresetDeleteRequest,
    ExecutionApprovalRequest,
    ExecutionApprovalDecisionRequest,
    ChannelInboundMessageRequest,
    ChannelTaskDispatchRequest,
    FeishuOutboundRequest,
    FeishuConfigUpdateRequest,
    FeishuConfigTestRequest,
    VisionNextActionRequest,
    NodeRegisterRequest,
    NodeHeartbeatRequest,
    NodeSelectRequest,
)
from models.response import ChatResponse, MemoryResponse

# åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆoverride=True ç¡®ä¿ .env æ–‡ä»¶ä¼˜å…ˆçº§é«˜äºç³»ç»Ÿç¯å¢ƒå˜é‡ï¼‰
load_dotenv(override=True)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)
_STARTUP_PROFILE_ENABLED = os.getenv("STARTUP_PROFILE", "1").strip().lower() in {"1", "true", "yes", "on"}
_STARTUP_T0 = time.perf_counter()
_startup_marks: list[dict] = []


def _startup_mark(step: str) -> None:
    if not _STARTUP_PROFILE_ENABLED:
        return
    now = time.perf_counter()
    elapsed_ms = int((now - _STARTUP_T0) * 1000)
    prev_ms = _startup_marks[-1]["elapsed_ms"] if _startup_marks else 0
    _startup_marks.append({
        "step": step,
        "elapsed_ms": elapsed_ms,
        "delta_ms": elapsed_ms - prev_ms,
    })


def _startup_report() -> None:
    if not _STARTUP_PROFILE_ENABLED:
        return
    if not _startup_marks:
        logger.info("å¯åŠ¨è€—æ—¶å‰–æå·²å¯ç”¨ï¼Œä½†æ²¡æœ‰å¯ç”¨çš„é˜¶æ®µæ•°æ®ã€‚")
        return
    parts = [f"{item['step']} +{item['delta_ms']}ms (ç´¯è®¡ {item['elapsed_ms']}ms)" for item in _startup_marks]
    logger.info("å¯åŠ¨è€—æ—¶å‰–æ: %s", " | ".join(parts))


_startup_mark("load_dotenv")

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="CKS Lite Agent SDK",
    description="è½»é‡çº§æ¡Œé¢ AI å·¥ä½œå° - Agent æœåŠ¡",
    version="0.1.0"
)

# CORS é…ç½®ï¼ˆå…è®¸ Tauri è®¿é—®ï¼‰
default_cors_origins = [
    "tauri://localhost",
    "http://localhost:1420",
    "http://127.0.0.1:1420",
    "http://localhost:5173",
    "http://127.0.0.1:5173",
]
cors_origins = os.getenv("CORS_ALLOW_ORIGINS", "").strip()
if cors_origins:
    allow_origins = [item.strip() for item in cors_origins.split(",") if item.strip()]
else:
    allow_origins = default_cors_origins

allow_credentials = "*" not in allow_origins
app.add_middleware(
    CORSMiddleware,
    allow_origins=allow_origins,
    allow_credentials=allow_credentials,
    allow_methods=["*"],
    allow_headers=["*"],
)
_startup_mark("fastapi_app_ready")

# åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
DATA_DIR = Path(os.getenv("DATA_DIR", "./data"))
DATA_DIR.mkdir(exist_ok=True)

memory_manager = MemoryManager(data_dir=DATA_DIR)
goal_manager = GoalManager(data_dir=DATA_DIR)
approval_store = ExecutionApprovalStore(data_dir=DATA_DIR)
channel_task_queue = ChannelTaskQueue(data_dir=DATA_DIR)
node_registry = NodeRegistry(data_dir=DATA_DIR)
autonomy_store = AutonomyStateStore(data_dir=DATA_DIR)
subagent_runtime_tasks: dict[str, asyncio.Task] = {}
FEISHU_CONFIG_PATH = DATA_DIR / "feishu_config.json"
_startup_mark("core_stores_ready")


def _load_feishu_config() -> dict:
    config = {
        "app_id": os.getenv("FEISHU_APP_ID", ""),
        "app_secret": os.getenv("FEISHU_APP_SECRET", ""),
        "verification_token": os.getenv("FEISHU_VERIFICATION_TOKEN", ""),
        "encrypt_key": os.getenv("FEISHU_ENCRYPT_KEY", ""),
        "domain": os.getenv("FEISHU_DOMAIN", "feishu"),
        "signature_tolerance_sec": int(os.getenv("FEISHU_SIGNATURE_TOLERANCE_SEC", "300")),
        "replay_cache_size": int(os.getenv("FEISHU_REPLAY_CACHE_SIZE", "2048")),
        "auto_dispatch": os.getenv("FEISHU_AUTO_DISPATCH", "1").strip().lower() not in {"0", "false", "off"},
        "enable_approval_card": os.getenv("FEISHU_ENABLE_APPROVAL_CARD", "1").strip().lower() not in {"0", "false", "off"},
        "allowed_senders": os.getenv("FEISHU_ALLOWED_SENDERS", "").strip(),
    }
    if FEISHU_CONFIG_PATH.exists():
        try:
            data = json.loads(FEISHU_CONFIG_PATH.read_text(encoding="utf-8"))
            if isinstance(data, dict):
                config.update({k: data.get(k, v) for k, v in config.items()})
        except Exception as e:
            logger.warning(f"è¯»å–é£ä¹¦é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
    return config


def _save_feishu_config(config: dict) -> None:
    FEISHU_CONFIG_PATH.write_text(json.dumps(config, ensure_ascii=False, indent=2), encoding="utf-8")


def _redact_feishu_config(config: dict) -> dict:
    data = dict(config)
    for key in ("app_secret", "verification_token", "encrypt_key"):
        value = str(data.get(key) or "")
        if not value:
            data[key] = ""
            continue
        data[key] = f"{value[:3]}***{value[-2:]}" if len(value) > 6 else "***"
    return data


def _resolve_secret_field(field_name: str, incoming_value: str) -> str:
    """If UI sends a redacted placeholder, keep the currently stored secret."""
    incoming = (incoming_value or "").strip()
    if incoming == "":
        return ""
    current_raw = str(feishu_runtime_config.get(field_name) or "")
    if current_raw and incoming == _redact_feishu_config({field_name: current_raw}).get(field_name):
        return current_raw
    return incoming


feishu_runtime_config = _load_feishu_config()
feishu_adapter = FeishuAdapter(
    app_id=feishu_runtime_config.get("app_id", ""),
    app_secret=feishu_runtime_config.get("app_secret", ""),
    verification_token=feishu_runtime_config.get("verification_token", ""),
    encrypt_key=feishu_runtime_config.get("encrypt_key", ""),
    domain=feishu_runtime_config.get("domain", "feishu"),
    timestamp_tolerance_sec=int(feishu_runtime_config.get("signature_tolerance_sec", 300)),
    replay_cache_size=int(feishu_runtime_config.get("replay_cache_size", 2048)),
)
_feishu_inbound_recent: dict[str, float] = {}
_FEISHU_INBOUND_DEBOUNCE_SEC = max(1.0, float(os.getenv("FEISHU_INBOUND_DEBOUNCE_SEC", "8")))
_startup_mark("feishu_adapter_ready")


def _apply_feishu_runtime_config(config: dict) -> None:
    feishu_runtime_config.update(config)
    feishu_adapter.app_id = str(feishu_runtime_config.get("app_id") or "").strip()
    feishu_adapter.app_secret = str(feishu_runtime_config.get("app_secret") or "").strip()
    feishu_adapter.verification_token = str(feishu_runtime_config.get("verification_token") or "").strip()
    feishu_adapter.encrypt_key = str(feishu_runtime_config.get("encrypt_key") or "").strip()
    feishu_adapter.domain = str(feishu_runtime_config.get("domain") or "feishu").strip().lower()
    feishu_adapter.base_url = "https://open.larksuite.com" if feishu_adapter.domain == "lark" else "https://open.feishu.cn"
    feishu_adapter.timestamp_tolerance_sec = max(0, int(feishu_runtime_config.get("signature_tolerance_sec") or 300))
    feishu_adapter.replay_cache_size = max(32, int(feishu_runtime_config.get("replay_cache_size") or 2048))
    feishu_adapter._token = None
    feishu_adapter._token_expire_at = 0.0


def _build_feishu_callback_urls(base_url: str) -> dict:
    root = (base_url or "").rstrip("/")
    return {
        "events": f"{root}/channels/feishu/events",
        "inbound": f"{root}/channels/feishu/inbound",
        "outbound": f"{root}/channels/feishu/outbound",
    }


def _build_feishu_diagnostic_checks(callback_urls: dict) -> list:
    checks = []
    app_id = str(feishu_runtime_config.get("app_id") or "").strip()
    app_secret = str(feishu_runtime_config.get("app_secret") or "").strip()
    verify_token = str(feishu_runtime_config.get("verification_token") or "").strip()
    encrypt_key = str(feishu_runtime_config.get("encrypt_key") or "").strip()
    domain = str(feishu_runtime_config.get("domain") or "feishu").strip().lower()
    signature_tolerance = int(feishu_runtime_config.get("signature_tolerance_sec") or 0)
    replay_cache_size = int(feishu_runtime_config.get("replay_cache_size") or 0)
    allowed_senders = str(feishu_runtime_config.get("allowed_senders") or "").strip()

    checks.append({
        "id": "credentials",
        "title": "åº”ç”¨å‡­æ®",
        "status": "pass" if app_id and app_secret else "fail",
        "detail": "å·²é…ç½® app_id + app_secretï¼Œå¯è·å– tenant_access_tokenã€‚" if app_id and app_secret else "ç¼ºå°‘ app_id æˆ– app_secretï¼Œé£ä¹¦æœºå™¨äººæ— æ³•è°ƒç”¨æ¶ˆæ¯ APIã€‚",
        "action": "åœ¨è®¾ç½®é¡µè¡¥é½ App ID / App Secretï¼Œå¹¶ç‚¹å‡»â€œæµ‹è¯•è¿é€šâ€ã€‚" if not (app_id and app_secret) else "",
    })
    checks.append({
        "id": "event_security",
        "title": "äº‹ä»¶å®‰å…¨é…ç½®",
        "status": "pass" if verify_token and encrypt_key else "warn",
        "detail": "verification_token ä¸ encrypt_key å·²é…ç½®ã€‚" if verify_token and encrypt_key else "å»ºè®®é…ç½® verification_token ä¸ encrypt_keyï¼Œæå‡å›è°ƒå®‰å…¨æ€§ã€‚",
        "action": "åˆ°é£ä¹¦äº‹ä»¶è®¢é˜…é¡µå¤åˆ¶ Token ä¸ Encrypt Keyã€‚" if not (verify_token and encrypt_key) else "",
    })
    checks.append({
        "id": "domain",
        "title": "é£ä¹¦åŒºåŸŸ",
        "status": "pass" if domain in {"feishu", "lark"} else "warn",
        "detail": "å½“å‰ä½¿ç”¨é£ä¹¦ä¸­å›½ç«™ã€‚" if domain == "feishu" else ("å½“å‰ä½¿ç”¨ Lark å›½é™…ç«™ã€‚" if domain == "lark" else f"æœªçŸ¥åŸŸåé…ç½®ï¼š{domain}"),
        "action": "æŒ‰ç§Ÿæˆ·æ‰€åœ¨åŒºåŸŸé€‰æ‹© feishu æˆ– larkã€‚" if domain not in {"feishu", "lark"} else "",
    })
    checks.append({
        "id": "signature_tolerance",
        "title": "ç­¾åæ—¶å·®å®¹å¿",
        "status": "pass" if 60 <= signature_tolerance <= 900 else "warn",
        "detail": f"å½“å‰ä¸º {signature_tolerance} ç§’ï¼Œæ¨èåŒºé—´ 60~900 ç§’ã€‚",
        "action": "å»ºè®®è®¾ç½®ä¸º 300 ç§’ï¼Œå…¼é¡¾å®‰å…¨ä¸æ—¶é’Ÿæ¼‚ç§»ã€‚" if not (60 <= signature_tolerance <= 900) else "",
    })
    checks.append({
        "id": "replay_cache",
        "title": "é‡æ”¾ç¼“å­˜å®¹é‡",
        "status": "pass" if replay_cache_size >= 256 else "warn",
        "detail": f"å½“å‰ç¼“å­˜å®¹é‡ {replay_cache_size}ï¼Œç”¨äºé˜²æ­¢ nonce/event_id é‡æ”¾ã€‚",
        "action": "å»ºè®®è‡³å°‘ 256ï¼Œç”Ÿäº§ç¯å¢ƒå¯è®¾ä¸º 2048ã€‚" if replay_cache_size < 256 else "",
    })
    checks.append({
        "id": "sender_allowlist",
        "title": "å‘é€è€…ç™½åå•",
        "status": "pass" if allowed_senders else "warn",
        "detail": "å·²å¯ç”¨ open_id ç™½åå•è¿‡æ»¤ã€‚" if allowed_senders else "å½“å‰æœªé…ç½®ç™½åå•ï¼Œä»»ä½•å¯è§¦è¾¾æœºå™¨äººçš„ç”¨æˆ·éƒ½èƒ½å‘èµ·è¯·æ±‚ã€‚",
        "action": "è‹¥æ˜¯ä¼ä¸šå†…ä½¿ç”¨ï¼Œå»ºè®®é…ç½® allowed_sendersï¼ˆé€—å·åˆ†éš” open_idï¼‰ã€‚" if not allowed_senders else "",
    })
    checks.append({
        "id": "callback_urls",
        "title": "å›è°ƒåœ°å€",
        "status": "pass",
        "detail": f"äº‹ä»¶å›è°ƒåœ°å€ï¼š{callback_urls.get('events', '')}",
        "action": "ç¡®ä¿è¯¥åœ°å€å¯è¢«é£ä¹¦å…¬ç½‘è®¿é—®ï¼›æœ¬åœ°è°ƒè¯•è¯·ç”¨å†…ç½‘ç©¿é€ã€‚" ,
    })
    return checks

# Skills åŠ è½½ï¼šæ”¯æŒå¤šæ¥æºæŠ€èƒ½ç›®å½•
# 1) agent-sdk/skillsï¼ˆå†…ç½®ï¼‰
# 2) ~/.agents/skillsï¼ˆç¤¾åŒºæŠ€èƒ½å¸¸ç”¨ç›®å½•ï¼‰
# 3) ~/.claude/skillsï¼ˆClaude Code ç”Ÿæ€ç›®å½•ï¼‰
# 4) CKS_EXTRA_SKILL_DIRSï¼ˆå¯é€‰ï¼Œé€—å·åˆ†éš”ï¼‰
_home_dir = Path.home()
_additional_skill_dirs = []
_disable_external_skills = os.getenv("CKS_DISABLE_EXTERNAL_SKILLS", "0").strip().lower() in {"1", "true", "yes", "on"}
if not _disable_external_skills:
    for _candidate in [
        _home_dir / ".agents" / "skills",
        _home_dir / ".claude" / "skills",
    ]:
        if _candidate.exists():
            _additional_skill_dirs.append(_candidate)
else:
    logger.info("å·²ç¦ç”¨å¤–éƒ¨ Skills ç›®å½•æ‰«æï¼ˆCKS_DISABLE_EXTERNAL_SKILLS=1ï¼‰")

_extra_skill_dirs_raw = os.getenv("CKS_EXTRA_SKILL_DIRS", "").strip()
if _extra_skill_dirs_raw:
    for _item in _extra_skill_dirs_raw.split(","):
        _dir = Path(_item.strip()).expanduser()
        if _dir.exists():
            _additional_skill_dirs.append(_dir)

skills_loader = SkillsLoader(additional_dirs=_additional_skill_dirs)
skill_installer = SkillInstaller(skills_dir=skills_loader.skills_dir)
skills_loader.annotate_sources(skill_installer.get_installed_skills())
_startup_mark("skills_loaded")
agent = ClaudeAgent(
    api_key=os.getenv("ANTHROPIC_API_KEY"),
    memory_manager=memory_manager,
    skills_loader=skills_loader,
    skill_installer=skill_installer,
    goal_manager=goal_manager,
    autonomy_store=autonomy_store,
)
_startup_mark("agent_ready")


def _build_bound_goal_task_context(goal_task_id):
    """Build compact task context for a bound goal task."""
    if goal_task_id is None:
        return ""
    try:
        task_id = int(goal_task_id)
    except Exception:
        return ""
    if task_id <= 0:
        return ""

    rows = goal_manager.list_tasks(task_id=task_id, limit=1)
    if not rows:
        return ""

    task = rows[0]
    state = goal_manager.get_execution_state(task_id) or {}
    profile = goal_manager.get_task_agent_profile(task_id, organization_id=task.get("organization_id")) or {}
    context_lines = [
        f"- task_id: {task_id}",
        f"- title: {task.get('title', '')}",
        f"- description: {task.get('description', '')}",
        f"- assignee: {task.get('assignee', '')}",
        f"- department: {task.get('department', '')}",
        f"- status: {task.get('status', '')}",
        f"- review_status: {task.get('review_status', '')}",
        f"- project: {task.get('project_title', '')}",
        f"- okr: {task.get('okr_title', '')}",
        f"- kpi: {task.get('kpi_title', '')}",
    ]
    if state:
        context_lines.extend([
            f"- execution_phase: {state.get('phase', '')}",
            f"- execution_state: {state.get('status', '')}",
            f"- execution_note: {state.get('note', '')}",
            f"- execution_prompt: {state.get('prompt', '')}",
        ])
    if profile:
        context_lines.extend([
            f"- agent_role: {profile.get('role', '')}",
            f"- agent_specialty: {profile.get('specialty', '')}",
            f"- preferred_skill: {profile.get('preferred_skill', '')}",
            f"- skill_stack: {', '.join(profile.get('skill_stack') or [])}",
            f"- skill_strict: {str(bool(profile.get('skill_strict'))).lower()}",
            f"- task_seed_prompt: {profile.get('seed_prompt', '')}",
        ])
    return "\n".join(context_lines)


def _inject_goal_task_context(message: str, goal_task_id):
    context = _build_bound_goal_task_context(goal_task_id)
    if not context:
        return message
    return (
        "ä½ å½“å‰ç»‘å®šäº†ä¸€ä¸ªç›®æ ‡ä»»åŠ¡ã€‚è¯·å°†å®ƒä½œä¸ºæœ¬è½®æ‰§è¡Œä¸Šä¸‹æ–‡ï¼Œä¸è¦å†å‘ç”¨æˆ·è¿½é—®â€œæ˜¯ä»€ä¹ˆä»»åŠ¡â€ã€‚\n"
        "è‹¥ç”¨æˆ·è¯´â€œåŸºäºè¿™ä¸ªä»»åŠ¡â€ï¼Œé»˜è®¤å°±æ˜¯ä¸‹æ–¹ç»‘å®šä»»åŠ¡ã€‚\n"
        "å¦‚æœéœ€è¦å›å†™ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€ï¼Œå¿…é¡»ä½¿ç”¨ goal_task_update å·¥å…·ï¼›ç¦æ­¢ç”¨ run_command å†™ä»»åŠ¡çŠ¶æ€ã€‚\n"
        "\n"
        "[BOUND_GOAL_TASK]\n"
        f"{context}\n"
        "[/BOUND_GOAL_TASK]\n"
        "\n"
        "ç”¨æˆ·æœ¬è½®è¾“å…¥ï¼š\n"
        f"{message}"
    )

# Auto-check office document dependencies on first startup
def _check_office_deps():
    """Check office document packages at startup."""
    if os.getenv("CKS_SKIP_DEPS_CHECK", "0").strip().lower() in {"1", "true", "yes", "on"}:
        logger.info("å·²è·³è¿‡ä¾èµ–æ£€æŸ¥ï¼ˆCKS_SKIP_DEPS_CHECK=1ï¼‰")
        return

    cache_file = DATA_DIR / "startup_deps_cache.json"
    cache_ttl_sec = max(60, int(os.getenv("CKS_DEPS_CHECK_CACHE_TTL_SEC", str(24 * 3600))))
    now_ts = int(time.time())
    try:
        if cache_file.exists():
            cache_data = json.loads(cache_file.read_text(encoding="utf-8"))
            checked_at = int(cache_data.get("checked_at", 0))
            if checked_at > 0 and (now_ts - checked_at) < cache_ttl_sec:
                logger.info(
                    "ä¾èµ–æ£€æŸ¥å‘½ä¸­ç¼“å­˜ï¼ˆ%ss å†…æœ‰æ•ˆï¼Œå‰©ä½™ %ssï¼‰",
                    cache_ttl_sec,
                    max(0, cache_ttl_sec - (now_ts - checked_at)),
                )
                return
    except Exception as cache_error:
        logger.warning(f"è¯»å–ä¾èµ–æ£€æŸ¥ç¼“å­˜å¤±è´¥ï¼Œå°†ç»§ç»­æ‰§è¡Œæ£€æŸ¥: {cache_error}")

    deps = {
        "openpyxl": "openpyxl", "pptx": "python-pptx", "docx": "python-docx",
        "fitz": "PyMuPDF", "matplotlib": "matplotlib", "PIL": "Pillow",
        "chardet": "chardet",
    }
    missing = []
    for import_name, pip_name in deps.items():
        try:
            __import__(import_name)
        except ImportError:
            missing.append(pip_name)

    if not missing:
        try:
            cache_file.write_text(json.dumps({
                "checked_at": now_ts,
                "missing": [],
                "auto_install": os.getenv("CKS_AUTO_INSTALL_DEPS", "0") == "1",
            }, ensure_ascii=False, indent=2), encoding="utf-8")
        except Exception as cache_write_error:
            logger.warning(f"å†™å…¥ä¾èµ–æ£€æŸ¥ç¼“å­˜å¤±è´¥: {cache_write_error}")
        return

    auto_install = os.getenv("CKS_AUTO_INSTALL_DEPS", "0") == "1"
    if not auto_install:
        logger.warning(
            "Missing office packages: %s. Auto install disabled; set CKS_AUTO_INSTALL_DEPS=1 to enable.",
            ", ".join(missing)
        )
        try:
            cache_file.write_text(json.dumps({
                "checked_at": now_ts,
                "missing": missing,
                "auto_install": False,
            }, ensure_ascii=False, indent=2), encoding="utf-8")
        except Exception as cache_write_error:
            logger.warning(f"å†™å…¥ä¾èµ–æ£€æŸ¥ç¼“å­˜å¤±è´¥: {cache_write_error}")
        return

    logger.info(f"Installing missing office packages: {', '.join(missing)}")
    import subprocess
    for pkg in missing:
        try:
            subprocess.run(
                [sys.executable, "-m", "pip", "install", pkg, "-q"],
                capture_output=True, timeout=120
            )
            logger.info(f"  Installed {pkg}")
        except Exception as e:
            logger.warning(f"  Failed to install {pkg}: {e}")

    try:
        cache_file.write_text(json.dumps({
            "checked_at": int(time.time()),
            "missing": missing,
            "auto_install": True,
        }, ensure_ascii=False, indent=2), encoding="utf-8")
    except Exception as cache_write_error:
        logger.warning(f"å†™å…¥ä¾èµ–æ£€æŸ¥ç¼“å­˜å¤±è´¥: {cache_write_error}")

_check_office_deps()
_startup_mark("deps_checked")


def _deploy_helpers():
    """Deploy helper scripts to user's temp dir for easy import."""
    import shutil
    scripts_dir = Path(__file__).parent / "scripts"
    temp_dir = Path(os.environ.get("TEMP", os.environ.get("TMP", "/tmp"))) / "cks_lite"
    temp_dir.mkdir(exist_ok=True)

    # éƒ¨ç½²æ‰€æœ‰åŠ©æ‰‹è„šæœ¬
    helper_files = [
        "cks_file_helpers.py",
        "cks_ppt_builder.py",
        "cks_email_sender.py",
    ]
    for filename in helper_files:
        src = scripts_dir / filename
        if src.exists():
            try:
                shutil.copy2(src, temp_dir / filename)
                logger.info(f"Deployed: {filename} -> {temp_dir / filename}")
            except Exception as e:
                logger.warning(f"Failed to deploy {filename}: {e}")

_deploy_helpers()
_startup_mark("helpers_deployed")

logger.info("Agent SDK åˆå§‹åŒ–å®Œæˆ")
logger.info(f"æ•°æ®ç›®å½•: {DATA_DIR.absolute()}")
logger.info(f"å·²åŠ è½½ Skills: {len(skills_loader.skills)} ä¸ª")
_startup_mark("bootstrap_complete")
_startup_report()


def _extract_mcp_tools_from_skill_md(skill_path: Path) -> list[str]:
    """Extract MCP tool references from SKILL.md for readiness diagnostics."""
    skill_md = skill_path / "SKILL.md"
    if not skill_md.exists():
        return []

    try:
        content = skill_md.read_text(encoding="utf-8", errors="ignore")
    except Exception:
        return []

    # Supports both mcp_server_tool and mcp__server__tool patterns.
    pattern = r"(mcp__[a-zA-Z0-9_]+__[a-zA-Z0-9_]+|mcp_[a-zA-Z0-9_]+(?:__[a-zA-Z0-9_]+)*)"
    seen = set()
    results = []
    for match in re.finditer(pattern, content):
        name = match.group(1)
        if name not in seen:
            seen.add(name)
            results.append(name)
    return results


def _check_skill_readiness(skill) -> dict:
    """
    Build a lightweight readiness report for a skill.

    Status values:
    - ready
    - missing_dependency
    - blocked_by_policy
    - runtime_error
    """
    status = "ready"
    message = "Skill is ready"
    required_tools = []
    runtime_checks = []

    # 1) Declared plugin tools from template.json
    if getattr(skill, "tools", None):
        for tool in skill.tools:
            required_tools.append(tool.name)
            if tool.entrypoint:
                module_path = tool.entrypoint.split(":")[0]
                module_file = skill.path / (module_path.replace(".", "/") + ".py")
                module_exists = module_file.exists()
                runtime_checks.append({
                    "name": f"entrypoint:{tool.name}",
                    "ok": module_exists,
                    "detail": str(module_file),
                })
                if not module_exists and status == "ready":
                    status = "missing_dependency"
                    message = f"Tool entrypoint file missing: {module_file.name}"

    # 2) MCP tool references from SKILL.md (e.g., openai-docs)
    mcp_tools = _extract_mcp_tools_from_skill_md(skill.path)
    if mcp_tools:
        required_tools.extend(mcp_tools)
        mcp_runtime_enabled = os.getenv("MCP_RUNTIME_ENABLED", "0") == "1"
        bridge_url = os.getenv("MCP_BRIDGE_URL", "").strip()
        if not bridge_url:
            host = os.getenv("HOST", "127.0.0.1")
            port = int(os.getenv("PORT", 7860))
            bridge_url = f"http://{host}:{port}/mcp/execute"
        runtime_checks.append({
            "name": "mcp_runtime",
            "ok": mcp_runtime_enabled,
            "detail": "Set MCP_RUNTIME_ENABLED=1 and configure MCP bridge/runtime",
        })
        runtime_checks.append({
            "name": "mcp_bridge_url",
            "ok": bool(bridge_url),
            "detail": bridge_url,
        })
        if not mcp_runtime_enabled and status == "ready":
            status = "missing_dependency"
            message = "MCP runtime is not configured"

    # 3) Optional policy block switch for emergency control
    if os.getenv("DISABLE_SKILLS_EXECUTION", "0") == "1":
        status = "blocked_by_policy"
        message = "Skills execution is disabled by policy (DISABLE_SKILLS_EXECUTION=1)"
        runtime_checks.append({
            "name": "skills_execution_policy",
            "ok": False,
            "detail": "DISABLE_SKILLS_EXECUTION=1",
        })

    # 4) Deduplicate required tools and keep stable output
    dedup_required = []
    seen_required = set()
    for t in required_tools:
        if t not in seen_required:
            seen_required.add(t)
            dedup_required.append(t)

    return {
        "name": skill.name,
        "display_name": skill.display_name,
        "source": getattr(skill, "source", "pre-installed"),
        "status": status,
        "message": message,
        "required_tools": dedup_required,
        "runtime_checks": runtime_checks,
    }


async def _run_skill_smoke_test(skill_name: str) -> dict:
    """Run a lightweight smoke test for a single skill."""
    skill = skills_loader.get_skill(skill_name)
    if not skill:
        return {"success": False, "error": f"Skill ä¸å­˜åœ¨: {skill_name}"}

    readiness = _check_skill_readiness(skill)
    if readiness["status"] != "ready":
        return {
            "success": False,
            "skill_name": skill_name,
            "status": readiness["status"],
            "message": readiness["message"],
            "checks": readiness["runtime_checks"],
        }

    # Context-only validation: SKILL.md readable when has_skill is true.
    context_ok = True
    context_len = 0
    if skill.has_skill:
        context = agent.skill_executor.get_skill_context(skill_name)
        context_ok = context is not None
        context_len = len(context or "")

    checks = [
        {"name": "skill_exists", "ok": True, "detail": str(skill.path)},
        {"name": "readiness_status", "ok": True, "detail": "ready"},
        {"name": "skill_context", "ok": context_ok, "detail": f"length={context_len}"},
    ]

    # Optional live probe for find-skills
    if skill_name in ("find-skills", "find_skills"):
        try:
            probe = await skill_installer.search_skills("productivity", limit=3)
            checks.append({
                "name": "live_probe_find_skills",
                "ok": isinstance(probe, list),
                "detail": f"results={len(probe) if isinstance(probe, list) else 0}",
            })
        except Exception as e:
            checks.append({
                "name": "live_probe_find_skills",
                "ok": False,
                "detail": str(e),
            })

    all_ok = all(c["ok"] for c in checks)
    return {
        "success": all_ok,
        "skill_name": skill_name,
        "status": "ready" if all_ok else "runtime_error",
        "message": "Smoke test passed" if all_ok else "Smoke test failed",
        "checks": checks,
    }


@app.get("/")
async def root():
    """????"""
    skills_meta = skills_loader.get_snapshot_meta()
    return {
        "status": "ok",
        "service": "CKS Lite Agent SDK",
        "version": "0.1.0",
        "skills_count": len(skills_loader.skills),
        "skills_snapshot_version": skills_meta.get("version"),
    }


@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """å¯¹è¯æ¥å£ï¼ˆéæµå¼ï¼‰"""
    try:
        effective_message = _inject_goal_task_context(request.message, request.goal_task_id)
        response_mode = (request.response_mode or "").strip().lower()
        if response_mode not in {"fast", "balanced", "deep"}:
            response_mode = "fast" if request.fast_mode else "fast"
        effective_use_memory = request.use_memory and response_mode != "fast"
        response = await agent.chat(
            user_id=request.user_id,
            message=effective_message,
            session_id=request.session_id,
            use_memory=effective_use_memory,
            fast_mode=(response_mode == "fast"),
            response_mode=response_mode,
            preferred_skill=request.preferred_skill,
            skill_strict=request.skill_strict,
        )

        return ChatResponse(
            message=response["message"],
            tool_calls=response.get("tool_calls", []),
            memory_used=response.get("memory_used", [])
        )
    except Exception as e:
        logger.error(f"å¯¹è¯é”™è¯¯: {e}", exc_info=True)
        return ChatResponse(
            message=f"æŠ±æ­‰ï¼Œå‘ç”Ÿé”™è¯¯: {str(e)}",
            tool_calls=[],
            memory_used=[]
        )


@app.post("/chat/stream")
async def chat_stream(request: ChatRequest):
    """????????????"""
    async def generate():
        has_successful_tool = False
        has_failed_tool = False
        stream_has_error = False
        try:
            effective_message = _inject_goal_task_context(request.message, request.goal_task_id)
            response_mode = (request.response_mode or "").strip().lower()
            if response_mode not in {"fast", "balanced", "deep"}:
                response_mode = "fast" if request.fast_mode else "fast"
            effective_use_memory = request.use_memory and response_mode != "fast"
            async for chunk in agent.chat_stream(
                user_id=request.user_id,
                message=effective_message,
                session_id=request.session_id,
                use_memory=effective_use_memory,
                fast_mode=(response_mode == "fast"),
                response_mode=response_mode,
                goal_task_id=request.goal_task_id,
                preferred_skill=request.preferred_skill,
                skill_strict=request.skill_strict,
            ):
                try:
                    parsed = json.loads(chunk)
                    if parsed.get("type") == "tool_result" and parsed.get("success"):
                        has_successful_tool = True
                    if parsed.get("type") == "tool_result" and parsed.get("success") is False:
                        has_failed_tool = True
                    if parsed.get("type") == "error":
                        stream_has_error = True
                    if (
                        parsed.get("type") == "done"
                        and request.goal_task_id
                        and has_successful_tool
                        and not has_failed_tool
                        and not stream_has_error
                    ):
                        goal_manager.complete_task(request.goal_task_id)
                except Exception:
                    pass
                yield f"data: {chunk}\n\n"
        except Exception as e:
            logger.error(f"?????????: {e}", exc_info=True)
            yield f"data: {{\"error\": \"{str(e)}\"}}\n\n"

    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # ç¦ç”¨ nginx ç¼“å†²
        }
    )


@app.post("/memory/save")
async def save_memory(request: MemoryRequest):
    """ä¿å­˜è®°å¿†"""
    try:
        memory_id = await memory_manager.save_memory(
            user_id=request.user_id,
            content=request.content,
            memory_type=request.memory_type,
            metadata=request.metadata
        )

        return {"success": True, "memory_id": memory_id}
    except Exception as e:
        logger.error(f"ä¿å­˜è®°å¿†é”™è¯¯: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/memory/search")
async def search_memory(user_id: str, query: str, top_k: int = 5):
    """æœç´¢è®°å¿†ï¼ˆçº¯å‘é‡æœç´¢ï¼‰"""
    try:
        memories = await memory_manager.search_memories(
            user_id=user_id,
            query=query,
            top_k=top_k,
            use_hybrid=False
        )

        return {
            "success": True,
            "memories": memories
        }
    except Exception as e:
        logger.error(f"æœç´¢è®°å¿†é”™è¯¯: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/memory/hybrid-search")
async def hybrid_search_memory(
    user_id: str,
    query: str,
    top_k: int = 5,
    vector_weight: float = 0.7,
    text_weight: float = 0.3,
    memory_type: str = None
):
    """æ··åˆæœç´¢è®°å¿†ï¼ˆBM25 + å‘é‡ï¼‰"""
    try:
        memories = await memory_manager.search_memories(
            user_id=user_id,
            query=query,
            top_k=top_k,
            memory_type=memory_type,
            use_hybrid=True
        )

        return {
            "success": True,
            "memories": memories,
            "search_params": {
                "vector_weight": vector_weight,
                "text_weight": text_weight,
                "top_k": top_k
            }
        }
    except Exception as e:
        logger.error(f"æ··åˆæœç´¢è®°å¿†é”™è¯¯: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/memory/search-v2")
async def search_memory_v2(
    user_id: str,
    query: str,
    top_k: int = 5,
    memory_type: str = None,
):
    """
    Two-stage memory recall (stage 1/search):
    return compact snippet list; client can call /memory/get by id for full content.
    """
    try:
        snippets = await memory_manager.search_memory_snippets(
            user_id=user_id,
            query=query,
            top_k=top_k,
            memory_type=memory_type,
            use_hybrid=True,
        )
        return {
            "success": True,
            "snippets": snippets,
            "total": len(snippets),
        }
    except Exception as e:
        logger.error(f"Memory search-v2 failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/memory/get")
async def get_memory_v2(user_id: str, memory_id: str):
    """
    Two-stage memory recall (stage 2/get):
    fetch full memory by id.
    """
    try:
        memory = await memory_manager.get_memory_detail(user_id=user_id, memory_id=memory_id)
        if not memory:
            return {"success": False, "error": "memory_not_found"}
        return {"success": True, "memory": memory}
    except Exception as e:
        logger.error(f"Memory get failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/memory/list")
async def list_memories(user_id: str, memory_type: str = None, limit: int = 50):
    """åˆ—å‡ºè®°å¿†"""
    try:
        memories = await memory_manager.list_memories(
            user_id=user_id,
            memory_type=memory_type,
            limit=limit
        )

        return {
            "success": True,
            "memories": memories,
            "total": len(memories)
        }
    except Exception as e:
        logger.error(f"åˆ—å‡ºè®°å¿†é”™è¯¯: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.delete("/memory/{memory_id}")
async def delete_memory(memory_id: str):
    """åˆ é™¤è®°å¿†"""
    try:
        await memory_manager.delete_memory(memory_id)
        return {"success": True}
    except Exception as e:
        logger.error(f"åˆ é™¤è®°å¿†é”™è¯¯: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/memory/{memory_id}/resolve-conflict")
async def resolve_memory_conflict(memory_id: str, action: str = "accept_current"):
    """Resolve memory conflict state for one memory and linked conflicting memories."""
    try:
        result = await memory_manager.resolve_conflict(memory_id=memory_id, action=action)
        return {"success": True, **result}
    except Exception as e:
        logger.error(f"Resolve memory conflict failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/memory/clear-all")
async def clear_all_memories(user_id: str, backup: bool = True):
    """
    æ¸…ç©ºæ‰€æœ‰è®°å¿†ï¼ˆå±é™©æ“ä½œï¼‰

    Args:
        user_id: ç”¨æˆ·ID
        backup: æ˜¯å¦åœ¨æ¸…ç©ºå‰å¤‡ä»½ï¼ˆé»˜è®¤ Trueï¼‰

    Returns:
        success: æ˜¯å¦æˆåŠŸ
        backup_path: å¤‡ä»½æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœ backup=Trueï¼‰
        cleared_count: æ¸…ç©ºçš„è®°å¿†æ•°é‡
    """
    try:
        logger.warning(f"âš ï¸ å±é™©æ“ä½œ: ç”¨æˆ· {user_id} è¯·æ±‚æ¸…ç©ºæ‰€æœ‰è®°å¿† (backup={backup})")

        # 1. ç»Ÿè®¡è¦æ¸…ç©ºçš„è®°å¿†æ•°é‡
        memories = await memory_manager.list_memories(user_id, limit=99999)
        total_count = len(memories)

        # 2. å¦‚æœéœ€è¦å¤‡ä»½ï¼Œå…ˆå¯¼å‡º
        backup_path = None
        if backup and memory_manager.markdown_memory:
            try:
                import json
                from datetime import datetime

                backup_data = memory_manager.markdown_memory.export_to_json()
                backup_filename = f"memory_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                backup_dir = memory_manager.data_dir / "backups"
                backup_dir.mkdir(exist_ok=True)
                backup_path = backup_dir / backup_filename

                with open(backup_path, "w", encoding="utf-8") as f:
                    json.dump(backup_data, f, indent=2, ensure_ascii=False)

                logger.info(f"âœ… å¤‡ä»½å·²ä¿å­˜: {backup_path}")
            except Exception as e:
                logger.error(f"å¤‡ä»½å¤±è´¥: {e}")
                return {
                    "success": False,
                    "error": f"å¤‡ä»½å¤±è´¥: {str(e)}",
                    "message": "ä¸ºäº†å®‰å…¨ï¼Œæ¸…ç©ºæ“ä½œå·²å–æ¶ˆ"
                }

        # 3. æ¸…ç©ºæ•°æ®åº“è®°å¿†
        conn = memory_manager._get_connection()
        cursor = conn.cursor()

        # åˆ é™¤æ‰€æœ‰è¯¥ç”¨æˆ·çš„è®°å¿†
        cursor.execute("DELETE FROM semantic_memories WHERE user_id = ?", (user_id,))
        cursor.execute("DELETE FROM semantic_memories_fts WHERE id IN (SELECT id FROM semantic_memories WHERE user_id = ?)", (user_id,))

        conn.commit()
        conn.close()

        # 4. æ¸…ç©º FAISS ç´¢å¼•ï¼ˆé‡å»ºç©ºç´¢å¼•ï¼‰
        if memory_manager.index and memory_manager.embedding_dim:
            import faiss
            memory_manager.index = faiss.IndexFlatL2(memory_manager.embedding_dim)
            faiss.write_index(memory_manager.index, str(memory_manager.index_path))

        # 5. æ¸…ç©º Markdown æ–‡ä»¶
        if memory_manager.markdown_memory:
            try:
                # é‡æ–°åˆå§‹åŒ– MEMORY.mdï¼ˆè¦†ç›–ä¸ºç©ºæ¨¡æ¿ï¼‰
                memory_manager.markdown_memory._initialize_memory_file()

                # åˆ é™¤æ‰€æœ‰æ¯æ—¥æ—¥å¿—ï¼ˆå¯é€‰ï¼Œè¿™é‡Œä¿ç•™æ—¥å¿—æ–‡ä»¶ï¼‰
                # å¦‚æœè¦åˆ é™¤æ—¥å¿—ï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Š
                # import shutil
                # if memory_manager.markdown_memory.daily_dir.exists():
                #     shutil.rmtree(memory_manager.markdown_memory.daily_dir)
                #     memory_manager.markdown_memory.daily_dir.mkdir()

                logger.info("âœ… Markdown æ–‡ä»¶å·²æ¸…ç©º")
            except Exception as e:
                logger.error(f"æ¸…ç©º Markdown å¤±è´¥: {e}")

        logger.warning(f"ğŸ—‘ï¸ å·²æ¸…ç©ºç”¨æˆ· {user_id} çš„æ‰€æœ‰è®°å¿† (å…± {total_count} æ¡)")

        return {
            "success": True,
            "cleared_count": total_count,
            "backup_path": str(backup_path) if backup_path else None,
            "message": f"å·²æˆåŠŸæ¸…ç©º {total_count} æ¡è®°å¿†" + (f"ï¼Œå¤‡ä»½å·²ä¿å­˜è‡³ {backup_path}" if backup_path else "")
        }

    except Exception as e:
        logger.error(f"æ¸…ç©ºè®°å¿†é”™è¯¯: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/memory/maintenance/compact")
async def compact_memories(
    user_id: str,
    dedupe_threshold: float = 0.985,
    stale_days: int = 120,
    dry_run: bool = False
):
    """Run memory anti-corrosion maintenance: deduplication + stale pruning."""
    try:
        result = await memory_manager.compact_memories(
            user_id=user_id,
            dedupe_threshold=dedupe_threshold,
            stale_days=stale_days,
            dry_run=dry_run,
        )
        return {"success": True, **result}
    except Exception as e:
        logger.error(f"Memory maintenance compact failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/memory/conflicts")
async def list_memory_conflicts(user_id: str, status: str = "pending_review", limit: int = 100):
    """List conflict queue for memory triage."""
    try:
        conflicts = await memory_manager.list_conflicts(user_id=user_id, status=status, limit=limit)
        return {"success": True, "conflicts": conflicts, "total": len(conflicts)}
    except Exception as e:
        logger.error(f"List memory conflicts failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/memory/maintenance/report")
async def memory_maintenance_report(
    user_id: str,
    dedupe_threshold: float = 0.985,
    stale_days: int = 120,
):
    """Return anti-corrosion inspection report without mutating data."""
    try:
        report = await memory_manager.get_maintenance_report(
            user_id=user_id,
            dedupe_threshold=dedupe_threshold,
            stale_days=stale_days,
        )
        return {"success": True, "report": report}
    except Exception as e:
        logger.error(f"Get memory maintenance report failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/memory/maintenance/auto-run")
async def memory_maintenance_auto_run(
    user_id: str,
    interval_hours: int = 24,
    force: bool = False,
    dedupe_threshold: float = 0.985,
    stale_days: int = 120,
):
    """Run scheduled anti-corrosion maintenance if due."""
    try:
        result = await memory_manager.run_scheduled_maintenance(
            user_id=user_id,
            interval_hours=interval_hours,
            force=force,
            dedupe_threshold=dedupe_threshold,
            stale_days=stale_days,
        )
        return {"success": True, **result}
    except Exception as e:
        logger.error(f"Auto memory maintenance failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/memory/markdown/read")
async def read_markdown_memory():
    """è¯»å– MEMORY.md å†…å®¹"""
    try:
        if not memory_manager.markdown_memory:
            return {"success": False, "error": "Markdown è®°å¿†ç³»ç»Ÿæœªå¯ç”¨"}

        content = memory_manager.markdown_memory.read_memory()
        memories = memory_manager.markdown_memory.parse_memories()

        return {
            "success": True,
            "content": content,
            "memories": memories,
            "file_path": str(memory_manager.markdown_memory.memory_file)
        }
    except Exception as e:
        logger.error(f"è¯»å– Markdown è®°å¿†é”™è¯¯: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/memory/markdown/daily-log")
async def read_daily_log(date: str = None):
    """è¯»å–æ¯æ—¥æ—¥å¿—"""
    try:
        if not memory_manager.markdown_memory:
            return {"success": False, "error": "Markdown è®°å¿†ç³»ç»Ÿæœªå¯ç”¨"}

        content = memory_manager.markdown_memory.read_daily_log(date)
        file_path = str(memory_manager.markdown_memory.daily_dir / f"{date or 'today'}.md")

        return {
            "success": True,
            "content": content,
            "date": date,
            "file_path": file_path
        }
    except Exception as e:
        logger.error(f"è¯»å–æ¯æ—¥æ—¥å¿—é”™è¯¯: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/memory/markdown/recent-logs")
async def get_recent_logs(days: int = 7):
    """è·å–æœ€è¿‘æ—¥å¿—åˆ—è¡¨"""
    try:
        if not memory_manager.markdown_memory:
            return {"success": False, "error": "Markdown è®°å¿†ç³»ç»Ÿæœªå¯ç”¨"}

        logs = memory_manager.markdown_memory.get_recent_logs(days)

        return {
            "success": True,
            "logs": logs
        }
    except Exception as e:
        logger.error(f"è·å–æœ€è¿‘æ—¥å¿—é”™è¯¯: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/skills")
async def list_skills():
    """???? Skills"""
    meta = skills_loader.get_snapshot_meta()
    return {
        "success": True,
        "skills": [skill.to_dict() for skill in skills_loader.skills],
        "snapshot": meta,
    }


@app.get("/skills/snapshot")
async def get_skills_snapshot():
    """Get current skills snapshot meta and optionally force refresh."""
    changed = skills_loader.refresh_if_changed()
    return {
        "success": True,
        "changed": changed,
        "snapshot": skills_loader.get_snapshot_meta(),
    }


@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥ï¼ˆå…¼å®¹è·¯å¾„ï¼‰"""
    return await root()


@app.get("/debug/startup-profile")
async def startup_profile():
    """æŸ¥çœ‹åç«¯å¯åŠ¨è€—æ—¶åˆ†è§£ï¼ˆç”¨äºæ€§èƒ½è°ƒä¼˜ï¼‰ã€‚"""
    return {
        "success": True,
        "enabled": _STARTUP_PROFILE_ENABLED,
        "total_ms": _startup_marks[-1]["elapsed_ms"] if _startup_marks else 0,
        "steps": _startup_marks,
    }


@app.get("/autonomy/events")
async def list_autonomy_events(
    session_id: str = None,
    goal_task_id: int = None,
    stage: str = None,
    limit: int = 200,
):
    """æŸ¥è¯¢è‡ªæ²»æ‰§è¡Œé˜¶æ®µäº‹ä»¶ï¼ˆç”¨äºå·¥ä½œå°å›æ”¾ä¸è°ƒè¯•ï¼‰ã€‚"""
    try:
        rows = autonomy_store.list_events(
            session_id=(session_id or "").strip() or None,
            goal_task_id=goal_task_id,
            stage=(stage or "").strip() or None,
            limit=limit,
        )
        return {"success": True, "events": rows}
    except Exception as e:
        logger.error(f"List autonomy events failed: {e}", exc_info=True)
        return {"success": False, "error": str(e), "events": []}


@app.post("/nodes/register")
async def register_node(request: NodeRegisterRequest):
    try:
        node = node_registry.register(
            node_id=request.node_id,
            organization_id=request.organization_id,
            display_name=request.display_name,
            host=request.host,
            os=request.os,
            arch=request.arch,
            status=request.status,
            capabilities=request.capabilities,
            metadata=request.metadata,
        )
        return {"success": True, "node": node}
    except Exception as e:
        logger.error(f"Register node failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/nodes")
async def list_nodes(
    organization_id: str = None,
    status: str = None,
    capability: str = None,
    limit: int = 100,
):
    try:
        items = node_registry.list(
            organization_id=organization_id,
            status=status,
            capability=capability,
            limit=limit,
        )
        return {"success": True, "items": items, "total": len(items)}
    except Exception as e:
        logger.error(f"List nodes failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/nodes/{node_id}")
async def get_node(node_id: str):
    try:
        item = node_registry.get(node_id)
        if not item:
            return {"success": False, "error": "Node not found"}
        return {"success": True, "node": item}
    except Exception as e:
        logger.error(f"Get node failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/nodes/select")
async def select_node(request: NodeSelectRequest):
    try:
        node = node_registry.select_best_node(
            organization_id=request.organization_id,
            capability=request.capability,
            preferred_os=request.preferred_os,
        )
        if not node:
            return {"success": False, "error": "No suitable node found"}
        return {"success": True, "node": node}
    except Exception as e:
        logger.error(f"Select node failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/nodes/{node_id}/heartbeat")
async def heartbeat_node(node_id: str, request: NodeHeartbeatRequest):
    try:
        item = node_registry.heartbeat(
            node_id=node_id,
            status=request.status,
            metadata=request.metadata,
        )
        if not item:
            return {"success": False, "error": "Node not found"}
        return {"success": True, "node": item}
    except Exception as e:
        logger.error(f"Node heartbeat failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/nodes/{node_id}/status")
async def set_node_status(node_id: str, request: NodeHeartbeatRequest):
    try:
        item = node_registry.set_status(node_id=node_id, status=request.status)
        if not item:
            return {"success": False, "error": "Node not found"}
        return {"success": True, "node": item}
    except Exception as e:
        logger.error(f"Set node status failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


async def _probe_mcp_bridge(bridge_url: str) -> tuple[bool, str]:
    """Probe MCP bridge reachability with a lightweight request."""
    try:
        async with httpx.AsyncClient(timeout=3.0) as client:
            resp = await client.post(
                bridge_url,
                json={"tool_name": "mcp__probe__ping", "tool_input": {}},
            )
        if resp.status_code in (200, 400):
            return True, f"http={resp.status_code}"
        return False, f"http={resp.status_code}"
    except Exception as e:
        return False, str(e)


def _iter_file_lines_reverse(file_path: Path, chunk_size: int = 8192):
    """Yield file lines in reverse order without loading the full file into memory."""
    with open(file_path, "rb") as f:
        f.seek(0, os.SEEK_END)
        file_size = f.tell()
        buffer = b""
        pos = file_size

        while pos > 0:
            read_size = min(chunk_size, pos)
            pos -= read_size
            f.seek(pos)
            chunk = f.read(read_size)
            buffer = chunk + buffer
            lines = buffer.split(b"\n")
            buffer = lines[0]
            for line in reversed(lines[1:]):
                if line:
                    yield line.decode("utf-8", errors="ignore")

        if buffer:
            yield buffer.decode("utf-8", errors="ignore")


def _read_audit_records(
    kind: str,
    session_id: str = None,
    tool_name: str = None,
    goal_task_id: int = None,
    from_time: str = None,
    to_time: str = None,
    limit: int = 100
) -> list:
    """
    Read audit JSONL records from data/audit.
    kind: execution | error
    """
    limit = max(1, min(limit, 1000))
    audit_dir = memory_manager.data_dir / "audit"
    if not audit_dir.exists():
        return []

    pattern = f"{kind}-*.jsonl"
    files = sorted(audit_dir.glob(pattern), reverse=True)
    records = []

    def parse_dt(value: str):
        if not value:
            return None
        try:
            normalized = value.replace("Z", "+00:00")
            return datetime.fromisoformat(normalized)
        except Exception:
            return None

    from_dt = parse_dt(from_time)
    to_dt = parse_dt(to_time)

    for file in files:
        try:
            line_iter = _iter_file_lines_reverse(file)
        except Exception:
            continue

        for line in line_iter:
            line = line.strip()
            if not line:
                continue
            try:
                row = json.loads(line)
            except Exception:
                continue

            # Backward-compatible key mapping for old/new audit schema
            if "timestamp" not in row and "ts" in row:
                row["timestamp"] = row.get("ts")
            if "tool_name" not in row and "tool" in row:
                row["tool_name"] = row.get("tool")
            if "tool_input" not in row and "input" in row:
                row["tool_input"] = row.get("input")

            if session_id and row.get("session_id") != session_id:
                continue

            normalized_tool_name = row.get("tool_name") or row.get("tool")
            if tool_name and normalized_tool_name != tool_name:
                continue
            if goal_task_id is not None and row.get("goal_task_id") != goal_task_id:
                continue

            row_time = parse_dt(row.get("timestamp") or row.get("ts"))
            if from_dt and row_time and row_time < from_dt:
                continue
            if to_dt and row_time and row_time > to_dt:
                continue

            records.append(row)
            if len(records) >= limit:
                return records

    return records


@app.get("/skills/readiness")
async def list_skills_readiness(skill_name: str = None):
    """Skill readiness diagnostics."""
    try:
        async def with_mcp_probe(row: dict) -> dict:
            has_mcp_tools = any(t.startswith("mcp_") or t.startswith("mcp__") for t in row.get("required_tools", []))
            mcp_enabled = os.getenv("MCP_RUNTIME_ENABLED", "0") == "1"
            if not has_mcp_tools or not mcp_enabled:
                return row

            bridge_url = os.getenv("MCP_BRIDGE_URL", "").strip()
            if not bridge_url:
                host = os.getenv("HOST", "127.0.0.1")
                port = int(os.getenv("PORT", 7860))
                bridge_url = f"http://{host}:{port}/mcp/execute"

            ok, detail = await _probe_mcp_bridge(bridge_url)
            checks = row.get("runtime_checks", [])
            checks.append({
                "name": "mcp_bridge_reachable",
                "ok": ok,
                "detail": detail,
            })
            row["runtime_checks"] = checks
            if not ok:
                row["status"] = "runtime_error"
                row["message"] = "MCP bridge is not reachable"
            return row

        if skill_name:
            skill = skills_loader.get_skill(skill_name)
            if not skill:
                return {"success": False, "error": f"Skill ä¸å­˜åœ¨: {skill_name}"}
            row = _check_skill_readiness(skill)
            row = await with_mcp_probe(row)
            return {"success": True, "readiness": [row]}

        readiness = []
        for skill in skills_loader.skills:
            row = _check_skill_readiness(skill)
            row = await with_mcp_probe(row)
            readiness.append(row)
        return {"success": True, "readiness": readiness, "total": len(readiness)}
    except Exception as e:
        logger.error(f"è·å– Skill readiness å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/audit/executions")
async def get_audit_executions(
    session_id: str = None,
    tool_name: str = None,
    goal_task_id: int = None,
    from_time: str = None,
    to_time: str = None,
    limit: int = 100
):
    """æŸ¥è¯¢å·¥å…·æ‰§è¡Œå®¡è®¡æ—¥å¿—"""
    try:
        rows = _read_audit_records(
            "execution",
            session_id=session_id,
            tool_name=tool_name,
            goal_task_id=goal_task_id,
            from_time=from_time,
            to_time=to_time,
            limit=limit
        )
        return {"success": True, "records": rows, "total": len(rows)}
    except Exception as e:
        logger.error(f"è¯»å– execution å®¡è®¡æ—¥å¿—å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/audit/errors")
async def get_audit_errors(
    session_id: str = None,
    tool_name: str = None,
    goal_task_id: int = None,
    from_time: str = None,
    to_time: str = None,
    limit: int = 100
):
    """æŸ¥è¯¢å·¥å…·é”™è¯¯å®¡è®¡æ—¥å¿—"""
    try:
        rows = _read_audit_records(
            "error",
            session_id=session_id,
            tool_name=tool_name,
            goal_task_id=goal_task_id,
            from_time=from_time,
            to_time=to_time,
            limit=limit
        )
        return {"success": True, "records": rows, "total": len(rows)}
    except Exception as e:
        logger.error(f"è¯»å– error å®¡è®¡æ—¥å¿—å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/skills/smoke-test")
async def smoke_test_skill(skill_name: str = None):
    """Run smoke test for one skill or all skills."""
    try:
        if skill_name:
            result = await _run_skill_smoke_test(skill_name)
            return {"success": result.get("success", False), "results": [result]}

        results = []
        for skill in skills_loader.skills:
            results.append(await _run_skill_smoke_test(skill.name))
        passed = len([r for r in results if r.get("success")])
        return {
            "success": True,
            "results": results,
            "summary": {
                "total": len(results),
                "passed": passed,
                "failed": len(results) - passed,
            }
        }
    except Exception as e:
        logger.error(f"Skill smoke test å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/mcp/execute")
async def mcp_execute(request: MCPExecuteRequest):
    """
    Local MCP bridge endpoint.
    This is a pragmatic fallback bridge for MCP-dependent skills before full MCP runtime integration.
    """
    try:
        tool_name = request.tool_name
        tool_input = request.tool_input or {}

        # Current fallback implementation for openaiDeveloperDocs MCP tools:
        # map MCP calls to domain-limited web search on developers.openai.com
        if "openaiDeveloperDocs" in tool_name:
            query = (
                tool_input.get("query")
                or tool_input.get("doc_id")
                or tool_input.get("path")
                or "OpenAI developer docs"
            )

            response = await agent.web_search.search(
                query=str(query),
                num_results=5,
                site="developers.openai.com",
                time_range=None
            )

            if not response.success:
                return {
                    "success": False,
                    "error": response.error or "Search failed",
                    "message": "openai docs fallback search failed"
                }

            if "search_openai_docs" in tool_name or "list_openai_docs" in tool_name:
                rows = []
                for i, r in enumerate(response.results, 1):
                    rows.append(f"{i}. {r.title}\n   {r.url}\n   {r.snippet[:220]}")
                return {
                    "success": True,
                    "message": f"æ‰¾åˆ° {len(response.results)} æ¡ OpenAI æ–‡æ¡£ç»“æœï¼ˆfallbackï¼‰",
                    "content": "\n\n".join(rows),
                    "data": {
                        "mode": "fallback_web_search",
                        "results": [
                            {"title": r.title, "url": r.url, "snippet": r.snippet}
                            for r in response.results
                        ]
                    }
                }

            # fetch_openai_doc fallback: return top result content/snippet
            top = response.results[0] if response.results else None
            return {
                "success": bool(top),
                "message": "è¿”å›æœ€ç›¸å…³æ–‡æ¡£ï¼ˆfallbackï¼‰" if top else "æœªæ‰¾åˆ°æ–‡æ¡£",
                "content": (top.content or top.snippet) if top else "",
                "data": {
                    "mode": "fallback_web_search",
                    "doc": {
                        "title": top.title,
                        "url": top.url,
                        "content": top.content or top.snippet
                    } if top else None
                }
            }

        return {
            "success": False,
            "error": f"Unsupported MCP tool: {tool_name}",
            "message": "æœ¬åœ° MCP bridge æš‚æœªæ”¯æŒè¯¥å·¥å…·ï¼Œè¯·æ¥å…¥å®Œæ•´ MCP runtimeã€‚"
        }
    except Exception as e:
        logger.error(f"MCP execute é”™è¯¯: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/skills/{skill_name}")
async def get_skill(skill_name: str):
    """è·å– Skill è¯¦æƒ…"""
    skill = skills_loader.get_skill(skill_name)
    if skill:
        return {"success": True, "skill": skill.to_dict()}
    else:
        return {"success": False, "error": "Skill ä¸å­˜åœ¨"}


@app.get("/skills/{skill_name}/context")
async def get_skill_context(skill_name: str):
    """è·å– Skill çš„ä¸Šä¸‹æ–‡ï¼ˆSKILL.md å†…å®¹ï¼‰"""
    context = agent.skill_executor.get_skill_context(skill_name)
    if context:
        return {"success": True, "context": context}
    else:
        return {"success": False, "error": "Skill ä¸Šä¸‹æ–‡ä¸å­˜åœ¨"}


@app.post("/skills/execute")
async def execute_skill(
    request: SkillExecuteRequest = None,
    skill_name: str = None,
    script_name: str = None,
):
    """æ‰§è¡Œ Skill è„šæœ¬"""
    try:
        # å…¼å®¹ä¸¤ç§è°ƒç”¨æ–¹å¼ï¼š
        # 1) ç°ä»£æ–¹å¼ï¼šå…¨éƒ¨å‚æ•°èµ° JSON body
        # 2) æ—§æ–¹å¼ï¼šskill_name/script_name åœ¨ queryï¼Œargs åœ¨ body
        resolved_skill_name = (request.skill_name if request else None) or skill_name
        resolved_script_name = (request.script_name if request else None) or script_name
        resolved_args = (request.args if request else None) or []

        if not resolved_skill_name or not resolved_script_name:
            return {
                "success": False,
                "error": "ç¼ºå°‘å‚æ•°: skill_name å’Œ script_name å¿…å¡«"
            }

        success, stdout, stderr = await agent.skill_executor.execute_script(
            skill_name=resolved_skill_name,
            script_name=resolved_script_name,
            args=resolved_args
        )

        return {
            "success": success,
            "stdout": stdout,
            "stderr": stderr
        }
    except Exception as e:
        logger.error(f"æ‰§è¡Œ Skill è„šæœ¬é”™è¯¯: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/skills/install")
async def install_skill(request: SkillInstallRequest):
    """ä» GitHub å®‰è£…ç¤¾åŒºæŠ€èƒ½"""
    try:
        result = await skill_installer.install_skill(request.ref)
        if result["success"]:
            skills_loader.reload()
            skills_loader.annotate_sources(skill_installer.get_installed_skills())
        return result
    except Exception as e:
        logger.error(f"å®‰è£…æŠ€èƒ½é”™è¯¯: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/skills/install/local")
async def install_local_skill(request: SkillLocalInstallRequest):
    """Install skill from local folder or zip path."""
    try:
        result = await skill_installer.install_local_skill(request.path)
        if result.get("success"):
            skills_loader.reload()
            skills_loader.annotate_sources(skill_installer.get_installed_skills())
        return result
    except Exception as e:
        logger.error(f"Install local skill error: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/skills/create")
async def create_skill(request: SkillCreateRequest):
    """Create a local skill scaffold."""
    try:
        result = await skill_installer.create_skill_scaffold(
            name=request.name,
            display_name=request.display_name,
            description=request.description,
            category=request.category,
            trigger_keywords=request.trigger_keywords,
            tags=request.tags,
        )
        if result.get("success"):
            skills_loader.reload()
            skills_loader.annotate_sources(skill_installer.get_installed_skills())
        return result
    except Exception as e:
        logger.error(f"Create skill scaffold error: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.delete("/skills/install/{skill_name}")
async def uninstall_skill(skill_name: str):
    """å¸è½½ç”¨æˆ·å®‰è£…çš„æŠ€èƒ½"""
    try:
        result = await skill_installer.uninstall_skill(skill_name)
        if result["success"]:
            skills_loader.reload()
            skills_loader.annotate_sources(skill_installer.get_installed_skills())
        return result
    except Exception as e:
        logger.error(f"å¸è½½æŠ€èƒ½é”™è¯¯: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/skills/installed")
async def list_installed_skills():
    """åˆ—å‡ºæ‰€æœ‰ç”¨æˆ·å®‰è£…çš„æŠ€èƒ½"""
    return {"success": True, "installed": skill_installer.get_installed_skills()}


@app.post("/tools/execute")
async def execute_tool(tool_name: str, tool_input: dict):
    """æ‰§è¡Œå·¥å…·è°ƒç”¨"""
    try:
        result = await agent.skill_executor.execute_tool(tool_name, tool_input)
        return result
    except Exception as e:
        logger.error(f"æ‰§è¡Œå·¥å…·é”™è¯¯: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/tools")
async def list_tools():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨å·¥å…·"""
    return {
        "success": True,
        "tools": agent.skill_executor.get_tool_definitions()
    }


@app.post("/vision/next-action")
async def vision_next_action(request: VisionNextActionRequest):
    """Visual planning API: infer next desktop action from screenshot + goal."""
    try:
        result = await agent.vision_next_action(
            image_path=request.image_path,
            goal=request.goal,
            history=request.history,
        )
        return result
    except Exception as e:
        logger.error(f"è§†è§‰ä¸‹ä¸€æ­¥è§„åˆ’å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/tools/desktop-result")
async def submit_desktop_result(request_id: str, result: dict):
    """
    Submit the result of a desktop tool execution from the frontend.
    The frontend calls this after executing a Tauri IPC command.
    """
    future = _desktop_results.get(request_id)
    if future and not future.done():
        future.set_result(result)
        logger.info(f"âœ… Desktop tool result received: {request_id}")
        return {"success": True}
    logger.warning(f"âš ï¸ No pending desktop tool request: {request_id}")
    return {"success": False, "error": "No pending request found for this request_id"}


async def _dispatch_channel_task_internal(
    task_id: int,
    user_id: str,
    session_id: str,
    use_memory: bool,
    message_override: str = "",
    execution_node_id: str = "",
):
    """Internal helper to dispatch queued channel task through agent chat path."""
    task = channel_task_queue.get(task_id)
    if not task:
        raise KeyError(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")

    channel_task_queue.mark_status(task_id, "running")
    dispatch_message = (message_override or "").strip() or task["message"]
    normalized_node_id = (execution_node_id or "").strip()
    if normalized_node_id:
        dispatch_message = (
            f"[æ‰§è¡ŒèŠ‚ç‚¹: {normalized_node_id}]\n"
            "è¯·ä¼˜å…ˆæŒ‰è¯¥èŠ‚ç‚¹èƒ½åŠ›æ‰§è¡Œä»»åŠ¡ï¼›è‹¥èŠ‚ç‚¹ä¸å¯ç”¨ï¼Œå…ˆè¯´æ˜åŸå› å¹¶ç»™å‡ºé™çº§æ–¹æ¡ˆã€‚\n\n"
            f"{dispatch_message}"
        )
    channel_response_mode = os.getenv("CHANNEL_TASK_RESPONSE_MODE", "fast").strip().lower()
    if channel_response_mode not in {"fast", "balanced", "deep"}:
        channel_response_mode = "fast"
    response = await agent.chat(
        user_id=user_id,
        message=dispatch_message,
        session_id=session_id,
        use_memory=use_memory,
        response_mode=channel_response_mode,
    )
    pending_approvals = approval_store.list_requests(status="pending", limit=50, session_id=session_id)
    final_status = "waiting_approval" if pending_approvals else "completed"
    updated = channel_task_queue.mark_status(
        task_id,
        final_status,
        result={
            "session_id": session_id,
            "dispatched_message": dispatch_message,
            "reply": response.get("message", ""),
            "tool_calls": response.get("tool_calls", []),
            "pending_approval_count": len(pending_approvals),
            "execution_node_id": normalized_node_id,
        },
    )
    return updated, response


def _build_subagent_prompt(
    task_row: dict,
    objective: str,
    assignee: str,
    role: str,
    specialty: str,
    seed_prompt: str,
    preferred_skill: str = "",
    skill_stack: list[str] | None = None,
) -> str:
    task_id = int(task_row.get("id") or 0)
    title = str(task_row.get("title") or "").strip()
    description = str(task_row.get("description") or "").strip()
    kpi = str(task_row.get("kpi_title") or "").strip()
    okr = str(task_row.get("okr_title") or "").strip()
    project = str(task_row.get("project_title") or "").strip()
    objective_text = objective.strip() or title or "å®Œæˆäº¤ä»˜ä»»åŠ¡"
    profile_line = f"ä½ æ˜¯{assignee}ï¼Œè§’è‰²={role or 'æ•°å­—å‘˜å·¥'}ï¼Œä¸“é•¿={specialty or 'é€šç”¨æ‰§è¡Œ'}ã€‚"
    stack_text = "ã€".join([s for s in (skill_stack or []) if s]) or "æ— "
    guidance = (
        "ä½ æ˜¯å¯é€šç”¨æ‰§è¡Œçš„æ•°å­—å‘˜å·¥ï¼Œç›®æ ‡æ˜¯åƒçœŸå®å‘˜å·¥ä¸€æ ·ç‹¬ç«‹å®Œæˆä»»åŠ¡ã€‚"
        "è¯·æŒ‰â€œè®¡åˆ’ -> æ‰§è¡Œ -> æ ¡éªŒ -> äº¤ä»˜â€çš„é¡ºåºæ¨è¿›ã€‚"
        "ä½ å¯ä»¥ä¸»åŠ¨è°ƒç”¨å¯ç”¨å·¥å…·ï¼ˆè”ç½‘æœç´¢ã€æ–‡ä»¶å¤„ç†ã€æ¡Œé¢è‡ªåŠ¨åŒ–ã€æŠ€èƒ½å·¥å…·ï¼‰ã€‚"
        "å½“ç°æœ‰æŠ€èƒ½ä¸å¤Ÿæ—¶ï¼Œå…ˆç”¨ find_skills æœç´¢ï¼Œå†ç”¨ install_skill å®‰è£…åç»§ç»­æ‰§è¡Œã€‚"
        "å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·å…ˆæå‡ºæœ€å¤š3ä¸ªæ¾„æ¸…é—®é¢˜ï¼›è‹¥å¯å…ˆåšå†é—®ï¼Œä¼˜å…ˆå…ˆäº§å‡ºå¯äº¤ä»˜åˆç¨¿ã€‚"
    )
    return (
        f"[å­Agentæ‰§è¡Œä»»åŠ¡]\n"
        f"- task_id: {task_id}\n"
        f"- KPI: {kpi}\n"
        f"- OKR: {okr}\n"
        f"- é¡¹ç›®: {project}\n"
        f"- ä»»åŠ¡æ ‡é¢˜: {title}\n"
        f"- ä»»åŠ¡æè¿°: {description or 'æ— '}\n"
        f"- æ‰§è¡Œç›®æ ‡: {objective_text}\n"
        f"- ä¸»æŠ€èƒ½åå¥½: {preferred_skill or 'è‡ªåŠ¨é€‰æ‹©'}\n"
        f"- å¯ç”¨æŠ€èƒ½æ ˆ: {stack_text}\n"
        f"{profile_line}\n"
        f"{guidance}\n"
        "äº¤ä»˜æ ¼å¼è¦æ±‚ï¼š\n"
        "1) æ‰§è¡Œè®¡åˆ’ï¼ˆ3-5æ¡ï¼‰\n"
        "2) å…³é”®æ‰§è¡Œè¿‡ç¨‹ï¼ˆå«ç”¨åˆ°çš„å·¥å…·/æŠ€èƒ½ï¼‰\n"
        "3) æœ€ç»ˆå¯äº¤ä»˜ç»“æœï¼ˆå¯ç›´æ¥ç»™ç”¨æˆ·ä½¿ç”¨ï¼‰\n"
        "4) éªŒæ”¶æ¸…å•ï¼ˆå¦‚ä½•åˆ¤æ–­å®Œæˆï¼‰\n"
        + (f"\né¢å¤–çº¦æŸï¼š{seed_prompt.strip()}\n" if seed_prompt.strip() else "")
    )


def _pick_subagent_response_mode(objective: str, task_row: dict) -> str:
    text = " ".join([
        str(objective or ""),
        str(task_row.get("title") or ""),
        str(task_row.get("description") or ""),
    ]).lower()
    heavy_keywords = [
        "ppt", "æ¼”ç¤º", "æŠ¥å‘Š", "è°ƒç ”", "æ–¹æ¡ˆ", "æ–‡æ¡£", "åˆ†æ", "è‡ªåŠ¨åŒ–", "çˆ¬å–", "æ•°æ®", "æ€»ç»“",
        "workflow", "analysis", "research", "slides", "report", "plan", "automation",
    ]
    score = sum(1 for k in heavy_keywords if k in text)
    if len(text) > 240 or score >= 2:
        return "deep"
    return "balanced"


def _has_structured_delivery_sections(message: str) -> bool:
    text = (message or "").strip().lower()
    if not text:
        return False
    required_groups = [
        ("æ‰§è¡Œè®¡åˆ’", "plan"),
        ("å…³é”®æ‰§è¡Œè¿‡ç¨‹", "æ‰§è¡Œè¿‡ç¨‹", "process"),
        ("æœ€ç»ˆå¯äº¤ä»˜ç»“æœ", "äº¤ä»˜ç»“æœ", "final deliverable", "deliverable"),
        ("éªŒæ”¶æ¸…å•", "acceptance checklist", "acceptance"),
    ]
    for group in required_groups:
        if not any(keyword.lower() in text for keyword in group):
            return False
    return True


def _get_subagent_retry_policy() -> tuple[int, float]:
    max_attempts = max(1, int(os.getenv("SUBAGENT_EXEC_MAX_ATTEMPTS", "2") or 2))
    backoff_sec = max(0.5, float(os.getenv("SUBAGENT_EXEC_BACKOFF_SEC", "1.5") or 1.5))
    return max_attempts, backoff_sec


def _get_subagent_timeout_policy() -> tuple[float, float]:
    soft_timeout = max(8.0, float(os.getenv("SUBAGENT_SOFT_TIMEOUT_SEC", "45") or 45))
    hard_timeout = max(soft_timeout + 5.0, float(os.getenv("SUBAGENT_HARD_TIMEOUT_SEC", "120") or 120))
    return soft_timeout, hard_timeout


def _compose_subagent_delivery_card(
    assignee: str,
    objective: str,
    risk_level: str,
    response_mode: str,
    attempt_used: int,
    tool_calls_count: int,
    used_repair: bool,
    strict_downgraded: bool,
    delivery: str,
) -> str:
    objective_text = (objective or "").strip() or "æŒ‰ä»»åŠ¡è¦æ±‚äº¤ä»˜"
    flags = []
    if used_repair:
        flags.append("å·²è§¦å‘äº¤ä»˜è¡¥å…¨")
    if strict_downgraded:
        flags.append("ä¸¥æ ¼æŠ€èƒ½å·²é™çº§ä¸ºé€šç”¨æ‰§è¡Œ")
    flag_text = "ï¼›".join(flags) if flags else "æ— "
    header = [
        "## æ‰§è¡Œæ‘˜è¦å¡",
        f"- è´Ÿè´£äººï¼š{assignee}",
        f"- ç›®æ ‡ï¼š{objective_text}",
        f"- é£é™©ç­‰çº§ï¼š{risk_level}",
        f"- æ‰§è¡Œæ¨¡å¼ï¼š{response_mode}",
        f"- é‡è¯•æ¬¡æ•°ï¼š{max(0, attempt_used - 1)}ï¼ˆæ€»å°è¯• {attempt_used} æ¬¡ï¼‰",
        f"- å·¥å…·è°ƒç”¨æ•°ï¼š{tool_calls_count}",
        f"- è‡ªåŠ¨æ¢å¤ï¼š{flag_text}",
        "",
        "---",
        "",
    ]
    return "\n".join(header) + (delivery or "").strip()


def _compose_subagent_failure_card(
    assignee: str,
    objective: str,
    risk_level: str,
    response_mode: str,
    attempt_used: int,
    tool_calls_count: int,
    used_repair: bool,
    strict_downgraded: bool,
    error_text: str,
) -> str:
    objective_text = (objective or "").strip() or "æŒ‰ä»»åŠ¡è¦æ±‚äº¤ä»˜"
    return "\n".join([
        "## æ‰§è¡Œå¤±è´¥æ¢å¤å¡",
        f"- è´Ÿè´£äººï¼š{assignee}",
        f"- ç›®æ ‡ï¼š{objective_text}",
        f"- é£é™©ç­‰çº§ï¼š{risk_level}",
        f"- æ‰§è¡Œæ¨¡å¼ï¼š{response_mode}",
        f"- å·²å°è¯•æ¬¡æ•°ï¼š{max(1, attempt_used)}",
        f"- å·¥å…·è°ƒç”¨æ•°ï¼š{tool_calls_count}",
        f"- è¿‡ç¨‹æ¢å¤ï¼š{'æ˜¯' if (used_repair or strict_downgraded) else 'å¦'}",
        "",
        "### å¤±è´¥åŸå› ",
        error_text or "æœªçŸ¥é”™è¯¯",
        "",
        "### å»ºè®®ä¸‹ä¸€æ­¥",
        "1) æ£€æŸ¥ä»»åŠ¡è¾“å…¥æ˜¯å¦å®Œæ•´ï¼ˆè¾“å…¥ä¿¡æ¯/æœŸæœ›è¾“å‡ºï¼‰ã€‚",
        "2) è‹¥æ¶‰åŠæŠ€èƒ½å·¥å…·ï¼Œå…ˆç¡®è®¤æŠ€èƒ½å¯ç”¨å¹¶é‡è¯•ã€‚",
        "3) è‹¥æ¶‰åŠå¤–éƒ¨ç³»ç»Ÿï¼Œå…ˆéªŒè¯ç½‘ç»œ/æƒé™åå†æ‰§è¡Œã€‚",
    ])


async def _call_subagent_chat_with_timeout(
    run_id: str,
    assignee: str,
    payload: dict,
) -> dict:
    soft_timeout, hard_timeout = _get_subagent_timeout_policy()
    task = asyncio.create_task(agent.chat(**payload))
    try:
        return await asyncio.wait_for(asyncio.shield(task), timeout=soft_timeout)
    except asyncio.TimeoutError:
        goal_manager.append_subagent_run_event(
            run_id,
            "clarify",
            f"{assignee} æ‰§è¡Œè¶…æ—¶é¢„è­¦ï¼ˆ>{int(soft_timeout)}sï¼‰ï¼Œç»§ç»­ç­‰å¾…ç»“æœã€‚",
            payload={"soft_timeout_sec": soft_timeout, "hard_timeout_sec": hard_timeout},
        )
        remain = max(1.0, hard_timeout - soft_timeout)
        try:
            return await asyncio.wait_for(asyncio.shield(task), timeout=remain)
        except asyncio.TimeoutError as timeout_err:
            task.cancel()
            raise RuntimeError(f"subagent_hard_timeout>{int(hard_timeout)}s") from timeout_err


def _assess_subagent_risk(task_row: dict, objective: str) -> tuple[str, str]:
    text = " ".join([
        str(task_row.get("title") or ""),
        str(task_row.get("description") or ""),
        str(objective or ""),
    ]).lower()
    high_keywords = [
        "åˆ é™¤", "æ¸…ç©º", "æ ¼å¼åŒ–", "rm ", "drop table", "è½¬è´¦", "æ‰“æ¬¾", "ä»˜æ¬¾", "æ”¯ä»˜", "æç°",
        "å¯†ç ", "éªŒè¯ç ", "token", "secret", "æ‰¹é‡å‘é€", "ç¾¤å‘",
    ]
    medium_keywords = [
        "é‚®ä»¶", "å‘ä¿¡", "å‘å¸ƒ", "å¯¼å‡º", "å†™æ–‡ä»¶", "ä¸‹è½½", "å®‰è£…", "æ‰§è¡Œè„šæœ¬", "run command",
    ]
    if any(keyword in text for keyword in high_keywords):
        return "high", "ä»»åŠ¡å«é«˜é£é™©å…³é”®è¯ï¼ˆèµ„é‡‘/åˆ é™¤/å‡­æ®/ç¾¤å‘ç­‰ï¼‰"
    if any(keyword in text for keyword in medium_keywords):
        return "medium", "ä»»åŠ¡æ¶‰åŠå¤–å‘/å®‰è£…/æ–‡ä»¶è½ç›˜ç­‰ä¸­é£é™©åŠ¨ä½œ"
    return "low", "å¸¸è§„å†…å®¹ä¸åˆ†æä»»åŠ¡"


async def _wait_subagent_approval(
    run_id: str,
    task_id: int,
    organization_id: str,
    objective: str,
    risk_level: str,
    risk_reason: str,
) -> tuple[bool, str]:
    require_levels = {
        level.strip().lower()
        for level in os.getenv("SUBAGENT_APPROVAL_LEVELS", "high").split(",")
        if level.strip()
    }
    auto_approve = os.getenv("SUBAGENT_AUTO_APPROVE", "0").strip().lower() in {"1", "true", "yes", "on"}
    if auto_approve or risk_level not in require_levels:
        return True, "skip"

    timeout_sec = max(10, int(os.getenv("SUBAGENT_APPROVAL_TIMEOUT_SEC", "120") or 120))
    request = approval_store.create_request(
        source="subagent_run",
        tool_name="subagent_execute",
        risk_level=risk_level,
        organization_id=organization_id,
        payload={
            "run_id": run_id,
            "task_id": task_id,
            "objective": (objective or "")[:400],
            "risk_reason": risk_reason,
        },
        ttl_seconds=timeout_sec,
    )
    request_id = str(request.get("id") or "")
    if not request_id:
        return False, "approval_create_failed"

    goal_manager.append_subagent_run_event(
        run_id,
        "clarify",
        f"æ£€æµ‹åˆ°{risk_level}é£é™©ï¼Œç­‰å¾…å®¡æ‰¹åç»§ç»­æ‰§è¡Œã€‚",
        payload={"approval_id": request_id, "risk_reason": risk_reason, "timeout_sec": timeout_sec},
    )
    deadline = time.time() + timeout_sec
    while time.time() < deadline:
        record = approval_store.get_request(request_id) or {}
        status = str(record.get("status") or "").lower()
        if status == "approved":
            return True, request_id
        if status in {"denied", "expired"}:
            return False, request_id
        await asyncio.sleep(2)
    return False, request_id


async def _run_subagent_task_async(
    run_id: str,
    task_id: int,
    organization_id: str,
    objective: str,
    supervisor_name: str,
    user_id: str = "default-user",
    auto_complete: bool = False,
):
    assignee = "å­Agent"
    risk_level = "unknown"
    response_mode = "balanced"
    objective_text = (objective or "").strip()
    attempt_used = 0
    tool_calls_count = 0
    used_repair = False
    strict_downgraded = False
    try:
        task_rows = goal_manager.list_tasks(
            organization_id=organization_id,
            task_id=task_id,
            limit=1,
        )
        if not task_rows:
            goal_manager.set_subagent_run_status(run_id, "failed", error_text="ä»»åŠ¡ä¸å­˜åœ¨æˆ–æ— æƒé™")
            goal_manager.append_subagent_run_event(run_id, "fallback", "ä»»åŠ¡ä¸å­˜åœ¨ï¼Œå­Agentè¿è¡Œç»“æŸã€‚")
            return
        task_row = task_rows[0]
        assignee = str(task_row.get("assignee") or "").strip() or "æœªåˆ†é…"
        objective_text = objective.strip() or str(task_row.get("title") or "")
        profile = goal_manager.get_task_agent_profile(task_id=task_id, organization_id=organization_id) or {}
        preferred_skill = str(profile.get("preferred_skill") or "").strip() or None
        skill_stack = [str(v).strip() for v in (profile.get("skill_stack") or []) if str(v).strip()]
        skill_strict = bool(profile.get("skill_strict"))
        role = str(profile.get("role") or "").strip()
        specialty = str(profile.get("specialty") or "").strip()
        seed_prompt = str(profile.get("seed_prompt") or "").strip()
        response_mode = _pick_subagent_response_mode(objective, task_row)
        risk_level, risk_reason = _assess_subagent_risk(task_row, objective)
        approved, approval_ref = await _wait_subagent_approval(
            run_id=run_id,
            task_id=task_id,
            organization_id=organization_id,
            objective=objective,
            risk_level=risk_level,
            risk_reason=risk_reason,
        )
        if not approved:
            goal_manager.set_subagent_run_status(run_id, "cancelled", error_text="å®¡æ‰¹æœªé€šè¿‡æˆ–è¶…æ—¶ï¼Œä»»åŠ¡æœªæ‰§è¡Œ")
            goal_manager.append_subagent_run_event(
                run_id,
                "fallback",
                "å®¡æ‰¹æœªé€šè¿‡æˆ–è¶…æ—¶ï¼Œå­Agentåœæ­¢æ‰§è¡Œã€‚",
                payload={"approval_id": approval_ref, "risk_level": risk_level, "risk_reason": risk_reason},
            )
            return

        goal_manager.set_subagent_run_status(run_id, "running")
        goal_manager.append_subagent_run_event(
            run_id,
            "planning",
            f"{supervisor_name} å·²å°†ä»»åŠ¡ä¸‹å‘ç»™ {assignee}ï¼Œå¼€å§‹ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ã€‚",
            payload={
                "assignee": assignee,
                "preferred_skill": preferred_skill or "",
                "skill_stack": skill_stack,
                "skill_strict": skill_strict,
                "response_mode": response_mode,
                "risk_level": risk_level,
                "risk_reason": risk_reason,
            },
        )
        goal_manager.update_execution_phase(
            task_id=task_id,
            phase="plan",
            status="active",
            note=f"{supervisor_name} -> {assignee} å­Agentæ‰§è¡Œä¸­",
            prompt=objective.strip() or str(task_row.get("title") or ""),
        )

        prompt = _build_subagent_prompt(
            task_row=task_row,
            objective=objective,
            assignee=assignee,
            role=role,
            specialty=specialty,
            seed_prompt=seed_prompt,
            preferred_skill=preferred_skill or "",
            skill_stack=skill_stack,
        )
        goal_manager.append_subagent_run_event(
            run_id,
            "execute",
            f"{assignee} å¼€å§‹æ‰§è¡Œä»»åŠ¡ï¼ˆæ¨¡å¼: {response_mode}ï¼‰ï¼Œæ­£åœ¨è°ƒç”¨ Agent + Skillsã€‚",
            payload={"step": "agent.chat", "response_mode": response_mode},
        )
        max_attempts, backoff_sec = _get_subagent_retry_policy()
        response = {}
        message = ""
        tool_calls = []
        for attempt in range(1, max_attempts + 1):
            attempt_mode = "deep" if attempt == max_attempts and max_attempts > 1 else response_mode
            try:
                response = await _call_subagent_chat_with_timeout(
                    run_id=run_id,
                    assignee=assignee,
                    payload={
                        "user_id": user_id,
                        "message": prompt,
                        "session_id": f"subagent-{run_id}",
                        "use_memory": True,
                        "fast_mode": False,
                        "response_mode": attempt_mode,
                        "preferred_skill": preferred_skill,
                        "skill_strict": skill_strict,
                    },
                )
                attempt_used = attempt
                message = str(response.get("message") or "").strip()
                tool_calls = response.get("tool_calls") or []
                tool_calls_count = len(tool_calls)
                if skill_strict and "æœªæ‰¾åˆ°ä½ æŒ‡å®šçš„æŠ€èƒ½" in message:
                    strict_downgraded = True
                    goal_manager.append_subagent_run_event(
                        run_id,
                        "fallback",
                        f"{assignee} æŒ‡å®šæŠ€èƒ½ä¸å¯ç”¨ï¼Œè‡ªåŠ¨åˆ‡æ¢ä¸ºé€šç”¨æ¨¡å¼é‡è¯•ã€‚",
                        payload={"preferred_skill": preferred_skill or "", "skill_strict": True},
                    )
                    response = await _call_subagent_chat_with_timeout(
                        run_id=run_id,
                        assignee=assignee,
                        payload={
                            "user_id": user_id,
                            "message": prompt,
                            "session_id": f"subagent-{run_id}",
                            "use_memory": True,
                            "fast_mode": False,
                            "response_mode": "deep",
                            "preferred_skill": None,
                            "skill_strict": False,
                        },
                    )
                    message = str(response.get("message") or "").strip()
                    tool_calls = response.get("tool_calls") or []
                    tool_calls_count = len(tool_calls)
                if message:
                    if attempt > 1:
                        goal_manager.append_subagent_run_event(
                            run_id,
                            "execute",
                            f"{assignee} åœ¨ç¬¬ {attempt} æ¬¡é‡è¯•åæˆåŠŸè·å–ç»“æœã€‚",
                            payload={"attempt": attempt, "response_mode": attempt_mode},
                        )
                    break
                raise RuntimeError("empty_message")
            except Exception as exec_err:
                goal_manager.append_subagent_run_event(
                    run_id,
                    "fallback",
                    f"æ‰§è¡Œå°è¯• {attempt}/{max_attempts} å¤±è´¥ï¼š{exec_err}",
                    payload={"attempt": attempt, "response_mode": attempt_mode},
                )
                if attempt >= max_attempts:
                    raise
                await asyncio.sleep(backoff_sec * attempt)

        need_repair = (
            not message
            or (len(message) < 120 and response_mode == "balanced")
            or not _has_structured_delivery_sections(message)
        )
        if need_repair:
            goal_manager.append_subagent_run_event(
                run_id,
                "clarify",
                f"{assignee} æ­£åœ¨è¡¥å……æ‰§è¡Œç»†èŠ‚ï¼Œäº§å‡ºé¦–ç‰ˆäº¤ä»˜ç‰©ã€‚",
                payload={
                    "reason": "result_empty_or_unstructured",
                    "tool_calls": tool_calls_count,
                    "has_structured_sections": _has_structured_delivery_sections(message),
                },
            )
            repair_prompt = (
                "è¯·ç»§ç»­å®Œå–„å½“å‰ä»»åŠ¡ï¼Œå¿…é¡»è¾“å‡ºå¯ç›´æ¥éªŒæ”¶çš„æœ€ç»ˆäº¤ä»˜ç»“æœã€‚\n"
                "è¦æ±‚ï¼šå¿…é¡»åŒ…å«å››ä¸ªä¸€çº§æ ‡é¢˜ï¼š\n"
                "# æ‰§è¡Œè®¡åˆ’\n# å…³é”®æ‰§è¡Œè¿‡ç¨‹\n# æœ€ç»ˆå¯äº¤ä»˜ç»“æœ\n# éªŒæ”¶æ¸…å•\n"
                "å¦‚æœéœ€è¦å¤–éƒ¨èƒ½åŠ›ï¼Œè¯·ä¸»åŠ¨æœç´¢/å®‰è£…æŠ€èƒ½å¹¶ç»§ç»­å®Œæˆï¼Œä¸è¦åªç»™å»ºè®®ã€‚"
            )
            used_repair = True
            repair = await _call_subagent_chat_with_timeout(
                run_id=run_id,
                assignee=assignee,
                payload={
                    "user_id": user_id,
                    "message": repair_prompt,
                    "session_id": f"subagent-{run_id}",
                    "use_memory": True,
                    "fast_mode": False,
                    "response_mode": "deep",
                    "preferred_skill": preferred_skill,
                    "skill_strict": skill_strict,
                },
            )
            repair_message = str(repair.get("message") or "").strip()
            if repair_message:
                message = repair_message
                tool_calls_count = len(repair.get("tool_calls") or [])
        if not message:
            message = "å­Agentæ‰§è¡Œå·²å®Œæˆï¼Œä½†æœªè¿”å›æ–‡æœ¬ç»“æœã€‚"
        final_message = _compose_subagent_delivery_card(
            assignee=assignee,
            objective=objective.strip() or str(task_row.get("title") or ""),
            risk_level=risk_level,
            response_mode=response_mode,
            attempt_used=max(attempt_used, 1),
            tool_calls_count=tool_calls_count,
            used_repair=used_repair,
            strict_downgraded=strict_downgraded,
            delivery=message,
        )

        goal_manager.append_subagent_run_event(
            run_id,
            "verify",
            f"{assignee} å·²å®Œæˆæ‰§è¡Œï¼Œæ­£åœ¨è¿›è¡Œäº¤ä»˜å‰æ ¡éªŒã€‚",
            payload={
                "reply_len": len(final_message),
                "attempt_used": max(attempt_used, 1),
                "tool_calls": tool_calls_count,
                "used_repair": used_repair,
                "strict_downgraded": strict_downgraded,
            },
        )
        goal_manager.update_execution_phase(
            task_id=task_id,
            phase="do",
            status="done",
            note=f"{assignee} å·²æäº¤æ‰§è¡Œç»“æœï¼Œå¯éªŒæ”¶",
            prompt=final_message[:1200],
        )
        goal_manager.append_subagent_run_event(
            run_id,
            "deliver",
            f"{assignee} å·²æäº¤å¯éªŒæ”¶ç»“æœã€‚",
            payload={
                "attempt_used": max(attempt_used, 1),
                "tool_calls": tool_calls_count,
                "risk_level": risk_level,
            },
        )
        if auto_complete:
            goal_manager.complete_task(task_id)
            goal_manager.append_subagent_run_event(
                run_id,
                "deliver",
                "ä»»åŠ¡çŠ¶æ€å·²è‡ªåŠ¨æ ‡è®°ä¸º doneï¼ˆå¾…éªŒæ”¶ï¼‰ã€‚",
            )
        goal_manager.set_subagent_run_status(run_id, "succeeded", result_text=final_message)
    except asyncio.CancelledError:
        goal_manager.set_subagent_run_status(run_id, "cancelled", error_text="è¿è¡Œè¢«å–æ¶ˆ")
        goal_manager.append_subagent_run_event(run_id, "fallback", "ä»»åŠ¡è¿è¡Œå·²å–æ¶ˆã€‚")
        raise
    except Exception as e:
        logger.error(f"Subagent run failed ({run_id}): {e}", exc_info=True)
        failure_card = _compose_subagent_failure_card(
            assignee=assignee,
            objective=objective_text,
            risk_level=risk_level,
            response_mode=response_mode,
            attempt_used=max(attempt_used, 1),
            tool_calls_count=tool_calls_count,
            used_repair=used_repair,
            strict_downgraded=strict_downgraded,
            error_text=str(e),
        )
        goal_manager.set_subagent_run_status(
            run_id,
            "failed",
            result_text=failure_card,
            error_text=str(e),
        )
        goal_manager.append_subagent_run_event(
            run_id,
            "fallback",
            f"æ‰§è¡Œå¤±è´¥ï¼Œå·²è¿›å…¥é€€è·¯æµç¨‹ï¼š{e}",
            payload={
                "attempt_used": max(attempt_used, 1),
                "tool_calls": tool_calls_count,
                "risk_level": risk_level,
            },
        )
    finally:
        subagent_runtime_tasks.pop(run_id, None)


def _infer_channel_task_node_capability(task: dict) -> str:
    """Infer desired node capability for channel task execution."""
    metadata = task.get("metadata") or {}
    explicit = str(
        metadata.get("execution_capability")
        or metadata.get("node_capability")
        or ""
    ).strip().lower()
    if explicit in {"desktop", "terminal", "vision"}:
        return explicit

    text = " ".join(
        [
            str(task.get("message") or ""),
            str(metadata.get("intent") or ""),
            str(metadata.get("tags") or ""),
        ]
    ).lower()
    if any(token in text for token in ["terminal", "shell", "å‘½ä»¤", "è„šæœ¬", "deploy", "git", "åç«¯"]):
        return "terminal"
    if any(token in text for token in ["vision", "æˆªå›¾", "å›¾åƒ", "ocr", "è¯†åˆ«", "screen"]):
        return "vision"
    return "desktop"


def _resolve_channel_task_execution_node(task: dict, requested_node_id: str = "") -> str:
    normalized_node_id = (requested_node_id or "").strip()
    if normalized_node_id:
        return normalized_node_id

    metadata = task.get("metadata") or {}
    organization_id = str(metadata.get("organization_id") or "default-org").strip() or "default-org"
    preferred_os = str(metadata.get("preferred_os") or "").strip().lower()
    capability = _infer_channel_task_node_capability(task)
    selected = node_registry.select_best_node(
        organization_id=organization_id,
        capability=capability,
        preferred_os=preferred_os,
    )
    if not selected:
        return ""
    return str(selected.get("node_id") or "").strip()


def _try_writeback_goal_task_from_channel_task(task: dict, response: dict) -> None:
    """Best-effort writeback to goal task when channel task metadata binds goal_task_id."""
    try:
        metadata = task.get("metadata") or {}
        goal_task_id_raw = metadata.get("goal_task_id")
        if goal_task_id_raw in (None, "", 0):
            return
        goal_task_id = int(goal_task_id_raw)
        note = f"æ¸ é“ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼ˆ{task.get('channel', 'channel')}ï¼‰\n\n{(response or {}).get('message', '')[:2000]}"
        goal_manager.update_execution_phase(
            goal_task_id,
            phase="verify",
            status="done",
            note=note,
            prompt=task.get("message", "")[:500],
        )
    except Exception as e:
        logger.warning(f"æ¸ é“ä»»åŠ¡å›å†™ Goals å¤±è´¥: {e}")


def _parse_feishu_text_message(message: dict, event: dict) -> str:
    content_value = message.get("content")
    if isinstance(content_value, str) and content_value.strip():
        try:
            parsed_content = json.loads(content_value)
            if isinstance(parsed_content, dict):
                if isinstance(parsed_content.get("text"), str):
                    return parsed_content.get("text", "").strip()
                # post/å¯Œæ–‡æœ¬åœºæ™¯ï¼šç®€å•æ‹¼æ¥å¯è¯»æ–‡æœ¬
                if isinstance(parsed_content.get("post"), dict):
                    segments = []
                    zh_cn = parsed_content.get("post", {}).get("zh_cn", {})
                    for row in zh_cn.get("content", []) if isinstance(zh_cn, dict) else []:
                        if not isinstance(row, list):
                            continue
                        for cell in row:
                            if isinstance(cell, dict) and isinstance(cell.get("text"), str):
                                segments.append(cell.get("text", "").strip())
                    if segments:
                        return " ".join([s for s in segments if s]).strip()
        except Exception:
            return content_value.strip()
    return str(event.get("text") or "").strip()


def _parse_feishu_command(text: str) -> dict:
    cleaned = (text or "").strip()
    if not cleaned:
        return {"cmd": "none"}
    normalized = cleaned.lower()
    if normalized in {"/cks help", "cks help", "/help", "å¸®åŠ©", "å‘½ä»¤"}:
        return {"cmd": "help"}
    if normalized in {"/cks commands", "cks commands"}:
        return {"cmd": "help"}
    if normalized in {"/cks status", "cks status", "çŠ¶æ€"}:
        return {"cmd": "status"}
    if normalized in {"/cks approvals", "cks approvals", "å®¡æ‰¹", "å¾…å®¡æ‰¹"}:
        return {"cmd": "approvals"}
    m = re.match(r"^(?:/cks\s+)?approve\s+([a-f0-9\-]{8,})$", normalized)
    if m:
        return {"cmd": "approve", "approval_id": m.group(1)}
    m = re.match(r"^(?:/cks\s+)?deny\s+([a-f0-9\-]{8,})$", normalized)
    if m:
        return {"cmd": "deny", "approval_id": m.group(1)}
    m = re.match(r"^(?:/cks\s+)?(?:pause|æš‚åœ)(?:\s+#?(\d+))?$", normalized)
    if m:
        return {"cmd": "pause", "task_id": int(m.group(1)) if m.group(1) else None}
    m = re.match(r"^(?:/cks\s+)?(?:resume|æ¢å¤|ç»§ç»­)(?:\s+#?(\d+))?$", normalized)
    if m:
        return {"cmd": "resume", "task_id": int(m.group(1)) if m.group(1) else None}
    m = re.match(r"^(?:/cks\s+)?(?:cancel|å–æ¶ˆ)(?:\s+#?(\d+))?$", normalized)
    if m:
        return {"cmd": "cancel", "task_id": int(m.group(1)) if m.group(1) else None}
    m = re.match(r"^(?:/cks\s+)?(?:retry|é‡è¯•)(?:\s+#?(\d+))?$", normalized)
    if m:
        return {"cmd": "retry", "task_id": int(m.group(1)) if m.group(1) else None}
    m = re.match(r"^(?:/cks\s+)?task\s+#?(\d+)$", normalized)
    if m:
        return {"cmd": "task", "goal_task_id": int(m.group(1))}
    m = re.match(r"^(?:/cks\s+)?run\s+(.+)$", cleaned, re.IGNORECASE)
    if m:
        return {"cmd": "run", "prompt": m.group(1).strip()}
    m = re.match(r"^(?:/cks\s+)?desktop\s+(.+)$", cleaned, re.IGNORECASE)
    if m:
        return {"cmd": "desktop", "prompt": m.group(1).strip()}
    m = re.match(r"^(?:/cks\s+)?computer\s+(.+)$", cleaned, re.IGNORECASE)
    if m:
        return {"cmd": "desktop", "prompt": m.group(1).strip()}
    return {"cmd": "none"}


def _parse_feishu_action_command(event: dict) -> dict:
    action = event.get("action") if isinstance(event, dict) else {}
    if not isinstance(action, dict):
        return {"cmd": "none"}
    value = action.get("value")
    if not isinstance(value, dict):
        return {"cmd": "none"}
    cmd = str(value.get("cmd") or "").strip().lower()
    if cmd in {"approve", "deny"}:
        return {"cmd": cmd, "approval_id": str(value.get("approval_id") or "").strip()}
    if cmd in {"pause", "resume", "cancel"}:
        task_id_raw = str(value.get("task_id") or "").strip()
        task_id = int(task_id_raw) if task_id_raw.isdigit() else None
        return {"cmd": cmd, "task_id": task_id}
    if cmd == "status":
        return {"cmd": "status"}
    if cmd == "help":
        return {"cmd": "help"}
    return {"cmd": "none"}


def _is_duplicate_feishu_inbound(chat_id: str, text: str) -> bool:
    normalized_text = " ".join((text or "").strip().lower().split())
    if not chat_id or not normalized_text:
        return False
    now = time.time()
    key = f"{chat_id}|{normalized_text}"
    last = _feishu_inbound_recent.get(key, 0.0)
    _feishu_inbound_recent[key] = now

    # Trim stale keys opportunistically.
    if len(_feishu_inbound_recent) > 1024:
        expire_before = now - (_FEISHU_INBOUND_DEBOUNCE_SEC * 3)
        for k, ts in list(_feishu_inbound_recent.items()):
            if ts < expire_before:
                _feishu_inbound_recent.pop(k, None)

    return (now - last) <= _FEISHU_INBOUND_DEBOUNCE_SEC


async def _try_send_feishu_chat_reply(receive_id: str, text: str, receive_id_type: str = "chat_id") -> None:
    if not receive_id or not text or not feishu_adapter.configured:
        return
    chunks = _split_feishu_text_chunks(text)
    try:
        for chunk in chunks:
            await feishu_adapter.send_text(
                receive_id=receive_id,
                receive_id_type=receive_id_type,
                text=chunk,
            )
    except Exception as e:
        logger.warning(f"å‘é€ Feishu å›æ‰§å¤±è´¥: {e}")


def _split_feishu_text_chunks(text: str, max_len: int = 900) -> list[str]:
    content = (text or "").strip()
    if not content:
        return []
    if len(content) <= max_len:
        return [content]

    chunks: list[str] = []
    current = ""
    paragraphs = [p.strip() for p in re.split(r"\n{2,}", content) if p.strip()]
    for paragraph in paragraphs:
        if len(paragraph) > max_len:
            if current:
                chunks.append(current)
                current = ""
            # Fallback: force split long paragraph by fixed length.
            for i in range(0, len(paragraph), max_len):
                chunks.append(paragraph[i:i + max_len])
            continue
        candidate = paragraph if not current else f"{current}\n\n{paragraph}"
        if len(candidate) <= max_len:
            current = candidate
            continue
        if current:
            chunks.append(current)
        current = paragraph
    if current:
        chunks.append(current)
    return chunks


def _format_feishu_help_text() -> str:
    return "\n".join(
        [
            "ã€CKS é£ä¹¦æŒ‡ä»¤ã€‘",
            "- /cks statusï¼šæŸ¥çœ‹ä»»åŠ¡ä¸å®¡æ‰¹çŠ¶æ€",
            "- /cks run <éœ€æ±‚>ï¼šç›´æ¥ä¸‹å‘é€šç”¨ä»»åŠ¡",
            "- /cks desktop <éœ€æ±‚>ï¼šä¼˜å…ˆèµ°æ¡Œé¢è‡ªåŠ¨åŒ–æ‰§è¡Œ",
            "- /cks task #<ä»»åŠ¡ID>ï¼šç»‘å®šç›®æ ‡ä»»åŠ¡åæ‰§è¡Œ",
            "- /cks approvalsï¼šæŸ¥çœ‹å¾…å®¡æ‰¹åˆ—è¡¨",
            "- approve <å®¡æ‰¹ID> / deny <å®¡æ‰¹ID>ï¼šå®¡æ‰¹å†³ç­–",
            "- /cks pause #<ä»»åŠ¡ID>ï¼šæš‚åœå¾…æ‰§è¡Œä»»åŠ¡",
            "- /cks resume #<ä»»åŠ¡ID>ï¼šæ¢å¤å¹¶ç»§ç»­æ‰§è¡Œ",
            "- /cks cancel #<ä»»åŠ¡ID>ï¼šå–æ¶ˆä»»åŠ¡",
            "- /cks retry #<ä»»åŠ¡ID>ï¼šé‡è¯•å¤±è´¥æˆ–å–æ¶ˆçš„ä»»åŠ¡",
        ]
    )


def _format_feishu_status_text(
    pending_tasks: int,
    running_tasks: int,
    waiting_approval_tasks: int,
    paused_tasks: int,
    pending_approvals: list[dict],
    chat_id: str = "",
) -> str:
    lines = [
        "ã€CKS çŠ¶æ€ã€‘",
        f"- å¾…æ´¾å‘ä»»åŠ¡: {pending_tasks}",
        f"- æ‰§è¡Œä¸­ä»»åŠ¡: {running_tasks}",
        f"- ç­‰å¾…å®¡æ‰¹ä»»åŠ¡: {waiting_approval_tasks}",
        f"- æš‚åœä»»åŠ¡: {paused_tasks}",
        f"- å¾…å®¡æ‰¹æ•°é‡: {len(pending_approvals)}",
    ]
    if pending_approvals:
        lines.append("- æœ€è¿‘å¾…å®¡æ‰¹:")
        for row in pending_approvals[:3]:
            lines.append(
                f"  â€¢ {row.get('id', '')[:8]}... | {row.get('tool_name', 'tool')} | é£é™© {row.get('risk_level', '-')}"
            )
        lines.append("- å¿«æ·å‘½ä»¤: approve <å®¡æ‰¹ID> / deny <å®¡æ‰¹ID>")
    else:
        lines.append("- å½“å‰æ— å¾…å®¡æ‰¹é¡¹ã€‚")
    recent_task_lines = _format_feishu_recent_tasks(chat_id=chat_id, limit=3)
    if recent_task_lines:
        lines.append("- æœ€è¿‘ä»»åŠ¡:")
        lines.extend(recent_task_lines)
    lines.append("- å¿«æ·å‘½ä»¤: /cks status | /cks pause #ä»»åŠ¡ID | /cks resume #ä»»åŠ¡ID | /cks cancel #ä»»åŠ¡ID | /cks retry #ä»»åŠ¡ID")
    return "\n".join(lines)


def _build_feishu_approval_card(approval: dict) -> dict:
    approval_id = str(approval.get("id") or "")
    short_id = f"{approval_id[:8]}..." if approval_id else "unknown"
    tool_name = str(approval.get("tool_name") or "tool")
    risk = str(approval.get("risk_level") or "-")
    return {
        "config": {"wide_screen_mode": True},
        "header": {
            "title": {"tag": "plain_text", "content": f"å¾…å®¡æ‰¹ | {short_id}"},
            "template": "orange" if risk.lower() in {"high", "medium"} else "blue",
        },
        "elements": [
            {
                "tag": "div",
                "text": {
                    "tag": "lark_md",
                    "content": f"**å·¥å…·**: `{tool_name}`\n**é£é™©**: `{risk}`\n**å®¡æ‰¹ID**: `{approval_id}`",
                },
            },
            {
                "tag": "note",
                "elements": [
                    {"tag": "plain_text", "content": "å¯ç›´æ¥å‘é€æŒ‡ä»¤ï¼šapprove <å®¡æ‰¹ID> æˆ– deny <å®¡æ‰¹ID>"},
                ],
            },
            {
                "tag": "action",
                "actions": [
                    {
                        "tag": "button",
                        "text": {"tag": "plain_text", "content": "æ‰¹å‡†"},
                        "type": "primary",
                        "value": {"cmd": "approve", "approval_id": approval_id},
                    },
                    {
                        "tag": "button",
                        "text": {"tag": "plain_text", "content": "æ‹’ç»"},
                        "type": "danger",
                        "value": {"cmd": "deny", "approval_id": approval_id},
                    },
                ],
            },
        ],
    }


def _build_feishu_approval_result_card(approval_id: str, status: str, operator: str, note: str = "") -> dict:
    normalized = (status or "").strip().lower()
    title = "å®¡æ‰¹å·²é€šè¿‡" if normalized == "approved" else "å®¡æ‰¹å·²æ‹’ç»" if normalized == "denied" else "å®¡æ‰¹çŠ¶æ€æ›´æ–°"
    template = "green" if normalized == "approved" else "red" if normalized == "denied" else "blue"
    lines = [
        f"**å®¡æ‰¹ID**: `{approval_id}`",
        f"**çŠ¶æ€**: `{normalized or status}`",
        f"**æ“ä½œäºº**: `{operator}`",
    ]
    if note:
        lines.append(f"**å¤‡æ³¨**: {note[:200]}")
    return {
        "config": {"wide_screen_mode": True},
        "header": {
            "title": {"tag": "plain_text", "content": title},
            "template": template,
        },
        "elements": [
            {
                "tag": "div",
                "text": {
                    "tag": "lark_md",
                    "content": "\n".join(lines),
                },
            }
        ],
    }


def _build_feishu_notice_card(title: str, body_lines: list[str], template: str = "blue") -> dict:
    return {
        "config": {"wide_screen_mode": True},
        "header": {
            "title": {"tag": "plain_text", "content": title[:60]},
            "template": template,
        },
        "elements": [
            {
                "tag": "div",
                "text": {
                    "tag": "lark_md",
                    "content": "\n".join([line for line in body_lines if line]).strip()[:1600],
                },
            }
        ],
    }


def _format_feishu_task_started(task_id: int, session_id: str, dispatch_message: str) -> str:
    preview = dispatch_message.strip().replace("\n", " ")
    if len(preview) > 80:
        preview = preview[:80] + "..."
    return "\n".join(
        [
            f"ã€ä»»åŠ¡å¼€å§‹ã€‘#{task_id}",
            f"- ä¼šè¯: {session_id}",
            f"- é˜¶æ®µ: å·²è¿›å…¥æ‰§è¡Œ",
            f"- æŒ‡ä»¤: {preview or '(ç©º)'}",
        ]
    )


def _format_feishu_task_done(task_id: int, status: str, tool_calls: list, final_text: str, pending_approval_count: int = 0) -> str:
    normalized_status = _normalize_channel_status(status)
    title = "ã€ä»»åŠ¡å¾…å®¡æ‰¹ã€‘" if normalized_status == "waiting_approval" else "ã€ä»»åŠ¡å®Œæˆã€‘"
    lines = [f"{title}#{task_id}", f"- å½“å‰çŠ¶æ€: {normalized_status}", f"- å·¥å…·è°ƒç”¨æ¬¡æ•°: {len(tool_calls)}"]
    if normalized_status == "waiting_approval":
        lines.append(f"- å¾…å®¡æ‰¹æ¡æ•°: {pending_approval_count}")
        lines.append("- æ“ä½œå»ºè®®: å…ˆæ‰§è¡Œ /cks approvals æŸ¥çœ‹å®¡æ‰¹ï¼Œå†æ‰§è¡Œ approve <å®¡æ‰¹ID>ã€‚")
    if final_text:
        lines.append("- ç»“æœæ‘˜è¦:")
        lines.append(final_text[:1000])
    return "\n".join(lines)


def _format_feishu_task_failed(task_id: int, error: Exception) -> str:
    return "\n".join(
        [
            f"ã€ä»»åŠ¡å¤±è´¥ã€‘#{task_id}",
            "- é˜¶æ®µ: æ‰§è¡Œä¸­æ–­",
            f"- é”™è¯¯: {str(error)}",
            "- å»ºè®®: å¯é‡è¯• run/desktop æŒ‡ä»¤ï¼Œæˆ–æ”¹ä¸ºæ›´æ˜ç¡®çš„æ­¥éª¤æè¿°ã€‚",
        ]
    )


def _is_allowed_feishu_sender(sender_open_id: str) -> bool:
    raw = str(feishu_runtime_config.get("allowed_senders") or "").strip()
    if not raw:
        return True
    allow = {item.strip() for item in raw.split(",") if item.strip()}
    if not allow:
        return True
    return sender_open_id in allow


def _resolve_approval_id(raw_id: str) -> str:
    value = (raw_id or "").strip().lower()
    if not value:
        return ""
    if len(value) >= 32:
        return value
    pending = approval_store.list_requests(status="pending", limit=200)
    matches = [
        str(item.get("id") or "")
        for item in pending
        if str(item.get("id") or "").lower().startswith(value)
    ]
    if len(matches) == 1:
        return matches[0]
    return value


def _normalize_channel_status(value: str) -> str:
    normalized = (value or "").strip().lower()
    alias_map = {
        "done": "completed",
        "complete": "completed",
        "success": "completed",
        "queued": "pending",
        "in_progress": "running",
        "waiting-approval": "waiting_approval",
        "waitingapproval": "waiting_approval",
        "awaiting_approval": "waiting_approval",
        "awaiting-approval": "waiting_approval",
        "paused": "paused",
        "cancelled": "canceled",
    }
    return alias_map.get(normalized, normalized)


def _channel_status_to_cn(status: str) -> str:
    mapping = {
        "pending": "å¾…æ‰§è¡Œ",
        "running": "æ‰§è¡Œä¸­",
        "waiting_approval": "å¾…å®¡æ‰¹",
        "paused": "å·²æš‚åœ",
        "completed": "å·²å®Œæˆ",
        "failed": "æ‰§è¡Œå¤±è´¥",
        "canceled": "å·²å–æ¶ˆ",
    }
    normalized = _normalize_channel_status(status)
    return mapping.get(normalized, normalized or "æœªçŸ¥")


def _format_feishu_recent_tasks(chat_id: str, limit: int = 3) -> list[str]:
    if not chat_id:
        return []
    rows = channel_task_queue.list_for_chat(channel="feishu", chat_id=chat_id, limit=max(1, min(limit, 8)))
    if not rows:
        return []
    lines: list[str] = []
    for row in rows[:limit]:
        task_id = int(row.get("id") or 0)
        status = _channel_status_to_cn(str(row.get("status") or ""))
        message = str(row.get("message") or "").strip().replace("\n", " ")
        if len(message) > 36:
            message = message[:36] + "..."
        lines.append(f"  â€¢ #{task_id} | {status} | {message or '(ç©ºæŒ‡ä»¤)'}")
    return lines


def _find_latest_feishu_task(chat_id: str, allowed_statuses: set[str] | None = None) -> dict | None:
    rows = channel_task_queue.list_for_chat(channel="feishu", chat_id=chat_id, limit=80)
    if not rows:
        return None
    if not allowed_statuses:
        return rows[0]
    for row in rows:
        if _normalize_channel_status(str(row.get("status") or "")) in allowed_statuses:
            return row
    return None


def _find_waiting_approval_task_for_record(chat_id: str, approval_record: dict) -> dict | None:
    rows = channel_task_queue.list_for_chat(channel="feishu", chat_id=chat_id, limit=80)
    if not rows:
        return None

    payload = approval_record.get("payload") if isinstance(approval_record, dict) else {}
    payload = payload if isinstance(payload, dict) else {}
    approval_session_id = str(payload.get("session_id") or "").strip()

    waiting_rows = [
        row
        for row in rows
        if _normalize_channel_status(str(row.get("status") or "")) == "waiting_approval"
    ]
    if not waiting_rows:
        return None
    if not approval_session_id:
        return waiting_rows[0]

    for row in waiting_rows:
        result = row.get("result") if isinstance(row.get("result"), dict) else {}
        task_session_id = str(result.get("session_id") or "").strip()
        if task_session_id and task_session_id == approval_session_id:
            return row
    return waiting_rows[0]


def _extract_dispatch_message(task: dict) -> str:
    result = task.get("result") if isinstance(task.get("result"), dict) else {}
    dispatched = str(result.get("dispatched_message") or "").strip()
    if dispatched:
        return dispatched
    return str(task.get("message") or "").strip()


def _control_channel_task(task: dict, action: str) -> tuple[dict | None, str]:
    task_id = int(task.get("id") or 0)
    if task_id <= 0:
        return None, "ä»»åŠ¡ä¸å­˜åœ¨ã€‚"
    status = _normalize_channel_status(str(task.get("status") or "pending"))

    if action == "pause":
        if status == "pending":
            updated = channel_task_queue.mark_status(task_id, "paused")
            return updated, f"ä»»åŠ¡ #{task_id} å·²æš‚åœã€‚"
        if status == "paused":
            return task, f"ä»»åŠ¡ #{task_id} å·²ç»æ˜¯æš‚åœçŠ¶æ€ã€‚"
        if status == "running":
            return task, f"ä»»åŠ¡ #{task_id} æ­£åœ¨æ‰§è¡Œï¼Œå½“å‰ç‰ˆæœ¬æš‚ä¸æ”¯æŒä¸­æ–­è¿è¡Œä¸­çš„ä»»åŠ¡ã€‚"
        return task, f"ä»»åŠ¡ #{task_id} å½“å‰çŠ¶æ€ä¸º {status}ï¼Œæ— æ³•æš‚åœã€‚"

    if action == "resume":
        if status in {"paused", "waiting_approval"}:
            updated = channel_task_queue.mark_status(task_id, "pending")
            return updated, f"ä»»åŠ¡ #{task_id} å·²æ¢å¤åˆ°å¾…æ‰§è¡Œé˜Ÿåˆ—ã€‚"
        if status == "pending":
            return task, f"ä»»åŠ¡ #{task_id} å·²åœ¨å¾…æ‰§è¡Œé˜Ÿåˆ—ä¸­ã€‚"
        if status == "running":
            return task, f"ä»»åŠ¡ #{task_id} æ­£åœ¨æ‰§è¡Œä¸­ï¼Œæ— éœ€æ¢å¤ã€‚"
        return task, f"ä»»åŠ¡ #{task_id} å½“å‰çŠ¶æ€ä¸º {status}ï¼Œæ— æ³•æ¢å¤ã€‚"

    if action == "cancel":
        if status in {"pending", "paused", "waiting_approval"}:
            updated = channel_task_queue.mark_status(task_id, "canceled")
            return updated, f"ä»»åŠ¡ #{task_id} å·²å–æ¶ˆã€‚"
        if status in {"completed", "failed", "canceled"}:
            return task, f"ä»»åŠ¡ #{task_id} å·²ç»“æŸï¼ˆ{status}ï¼‰ï¼Œæ— éœ€å–æ¶ˆã€‚"
        if status == "running":
            return task, f"ä»»åŠ¡ #{task_id} æ­£åœ¨æ‰§è¡Œï¼Œå½“å‰ç‰ˆæœ¬æš‚ä¸æ”¯æŒå¼ºåˆ¶ä¸­æ­¢ã€‚"
        return task, f"ä»»åŠ¡ #{task_id} å½“å‰çŠ¶æ€ä¸º {status}ï¼Œæ— æ³•å–æ¶ˆã€‚"

    return task, f"æš‚ä¸æ”¯æŒçš„æ§åˆ¶åŠ¨ä½œ: {action}"


def _prepare_retry_channel_task(task: dict) -> tuple[dict | None, str]:
    task_id = int(task.get("id") or 0)
    if task_id <= 0:
        return None, "ä»»åŠ¡ä¸å­˜åœ¨ã€‚"
    status = _normalize_channel_status(str(task.get("status") or "pending"))
    if status not in {"failed", "canceled"}:
        return task, f"ä»»åŠ¡ #{task_id} å½“å‰çŠ¶æ€ä¸º {status}ï¼Œä»…å¤±è´¥/å·²å–æ¶ˆä»»åŠ¡å¯é‡è¯•ã€‚"
    updated = channel_task_queue.mark_status(task_id, "pending")
    return updated, f"ä»»åŠ¡ #{task_id} å·²åŠ å…¥é‡è¯•é˜Ÿåˆ—ã€‚"


@app.post("/approvals/request")
async def create_execution_approval(request: ExecutionApprovalRequest):
    """åˆ›å»ºä¸€æ¡æ‰§è¡Œå®¡æ‰¹è®°å½•ï¼ˆä¾›é«˜é£é™©å·¥å…·/æ¸ é“ä»»åŠ¡å¤ç”¨ï¼‰"""
    try:
        record = approval_store.create_request(
            source=request.source,
            organization_id=request.organization_id,
            tool_name=request.tool_name,
            risk_level=request.risk_level,
            payload=request.payload,
            ttl_seconds=request.ttl_seconds,
        )
        return {"success": True, "record": record}
    except Exception as e:
        logger.error(f"åˆ›å»ºå®¡æ‰¹è¯·æ±‚å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/approvals")
async def list_execution_approvals(
    status: str = "",
    limit: int = 50,
    organization_id: str = "",
    session_id: str = "",
):
    """æŸ¥è¯¢å®¡æ‰¹è®°å½•"""
    try:
        items = approval_store.list_requests(
            status=status.strip() or None,
            limit=limit,
            organization_id=organization_id.strip() or None,
            session_id=session_id.strip() or None,
        )
        return {"success": True, "items": items, "total": len(items)}
    except Exception as e:
        logger.error(f"æŸ¥è¯¢å®¡æ‰¹è®°å½•å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/approvals/{request_id}/decision")
async def decide_execution_approval(request_id: str, request: ExecutionApprovalDecisionRequest):
    """å®¡æ‰¹é€šè¿‡/æ‹’ç»"""
    try:
        record = approval_store.decide_request(
            request_id=request_id,
            decision=request.decision,
            decided_by=request.decided_by,
            note=request.note,
        )
        return {"success": True, "record": record}
    except Exception as e:
        logger.error(f"å®¡æ‰¹å†³ç­–å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/channels/feishu/events")
async def feishu_events(payload: dict, request: Request):
    """
    Feishu/Lark äº‹ä»¶å…¥å£ï¼ˆMVPï¼‰ï¼š
    - å¤„ç† challenge
    - å¤„ç† message äº‹ä»¶å¹¶å…¥é˜Ÿ
    """
    try:
        if not isinstance(payload, dict):
            return {"success": False, "error": "invalid payload"}

        header_map = {k.lower(): v for k, v in request.headers.items()}
        raw_body = (await request.body()).decode("utf-8", errors="ignore")
        if not feishu_adapter.verify_event(payload, header_map, raw_body):
            return {"success": False, "error": "verification failed"}

        challenge = feishu_adapter.extract_challenge(payload)
        if challenge:
            return {"challenge": challenge}

        event = payload.get("event") or {}
        message = event.get("message") or {}
        sender = event.get("sender") or {}
        context = event.get("context") or {}
        operator = event.get("operator") or {}

        chat_id = str(
            message.get("chat_id")
            or event.get("chat_id")
            or context.get("open_chat_id")
            or context.get("chat_id")
            or ""
        ).strip()
        sender_open_id = str(
            (sender.get("sender_id") or {}).get("open_id")
            or operator.get("open_id")
            or ""
        ).strip()
        event_header = payload.get("header") if isinstance(payload.get("header"), dict) else {}
        event_id = str(event_header.get("event_id") or "").strip()
        message_id = str(message.get("message_id") or event.get("message_id") or "").strip()
        external_id = message_id or event_id
        text = _parse_feishu_text_message(message, event)

        cmd = _parse_feishu_action_command(event)
        if cmd.get("cmd") == "none":
            cmd = _parse_feishu_command(text)

        if not chat_id or (not text and cmd.get("cmd") == "none"):
            return {"success": True, "ignored": True, "reason": "missing chat_id or text"}
        if not _is_allowed_feishu_sender(sender_open_id):
            await _try_send_feishu_chat_reply(chat_id, "å½“å‰è´¦å·æœªåœ¨å…è®¸åˆ—è¡¨ä¸­ï¼Œè¯·è”ç³»ç®¡ç†å‘˜å¼€é€šã€‚")
            return {"success": False, "error": "sender not allowed"}
        if _is_duplicate_feishu_inbound(chat_id=chat_id, text=text):
            await _try_send_feishu_chat_reply(chat_id, "æ”¶åˆ°é‡å¤æŒ‡ä»¤ï¼Œå·²å¿½ç•¥æœ¬æ¬¡è¯·æ±‚ï¼ˆé˜²æŠ–ç”Ÿæ•ˆï¼Œé¿å…é‡å¤æ‰§è¡Œï¼‰ã€‚")
            return {"success": True, "ignored": True, "reason": "duplicate-inbound"}
        if external_id:
            existing_task = channel_task_queue.get_by_external_id(channel="feishu", external_id=external_id)
            if existing_task:
                await _try_send_feishu_chat_reply(
                    chat_id,
                    f"æ£€æµ‹åˆ°é‡å¤äº‹ä»¶ï¼Œä»»åŠ¡ #{existing_task.get('id')} å·²å­˜åœ¨ï¼ˆçŠ¶æ€: {_channel_status_to_cn(str(existing_task.get('status') or 'pending'))}ï¼‰ã€‚",
                )
                return {"success": True, "ignored": True, "reason": "duplicate-external-id", "task": existing_task}

        if cmd.get("cmd") == "help":
            await _try_send_feishu_chat_reply(chat_id, _format_feishu_help_text())
            return {"success": True, "handled": "help"}
        if cmd.get("cmd") in {"status", "approvals"}:
            pending_tasks = channel_task_queue.list(status="pending", channel="feishu", limit=100)
            running_tasks = channel_task_queue.list(status="running", channel="feishu", limit=100)
            waiting_approval_tasks = channel_task_queue.list(status="waiting_approval", channel="feishu", limit=100)
            paused_tasks = channel_task_queue.list(status="paused", channel="feishu", limit=100)
            pending_approvals = approval_store.list_requests(status="pending", limit=20)
            await _try_send_feishu_chat_reply(
                chat_id,
                _format_feishu_status_text(
                    len(pending_tasks),
                    len(running_tasks),
                    len(waiting_approval_tasks),
                    len(paused_tasks),
                    pending_approvals,
                    chat_id=chat_id,
                ),
            )
            send_cards = bool(feishu_runtime_config.get("enable_approval_card", True))
            if send_cards and feishu_adapter.configured:
                for approval in pending_approvals[:2]:
                    try:
                        await feishu_adapter.send_interactive(
                            receive_id=chat_id,
                            receive_id_type="chat_id",
                            card=_build_feishu_approval_card(approval),
                        )
                    except Exception as card_error:
                        logger.warning(f"å‘é€ Feishu å®¡æ‰¹å¡ç‰‡å¤±è´¥: {card_error}")
            return {"success": True, "handled": cmd.get("cmd")}
        if cmd.get("cmd") in {"pause", "resume", "cancel", "retry"}:
            requested_task_id = cmd.get("task_id")
            target = channel_task_queue.get(int(requested_task_id)) if requested_task_id else None
            if target and target.get("chat_id") != chat_id:
                await _try_send_feishu_chat_reply(chat_id, f"ä»»åŠ¡ #{requested_task_id} ä¸åœ¨å½“å‰ä¼šè¯å†…ï¼Œæ— æ³•ç›´æ¥æ§åˆ¶ã€‚")
                return {"success": False, "error": "task not in current chat"}
            if not target:
                allowed_statuses = {"pending", "paused", "waiting_approval", "running"}
                if str(cmd.get("cmd") or "") == "retry":
                    allowed_statuses = {"failed", "canceled"}
                target = _find_latest_feishu_task(
                    chat_id=chat_id,
                    allowed_statuses=allowed_statuses,
                )
            if not target:
                await _try_send_feishu_chat_reply(chat_id, "å½“å‰ä¼šè¯æ²¡æœ‰å¯æ§åˆ¶çš„ä»»åŠ¡ã€‚")
                return {"success": False, "error": "no controllable task"}

            current_cmd = str(cmd.get("cmd") or "")
            if current_cmd == "retry":
                updated, tip = _prepare_retry_channel_task(target)
            else:
                updated, tip = _control_channel_task(target, action=current_cmd)
            await _try_send_feishu_chat_reply(chat_id, tip)
            if current_cmd in {"resume", "retry"} and updated and _normalize_channel_status(str(updated.get("status") or "")) == "pending":
                try:
                    session_id = f"channel:feishu:{chat_id}"
                    action_desc = "å·²æ¢å¤" if current_cmd == "resume" else "å·²é‡è¯•"
                    await _try_send_feishu_chat_reply(chat_id, f"ã€è¿›åº¦ã€‘#{updated['id']} {action_desc}ï¼Œæ­£åœ¨é‡æ–°æ´¾å‘æ‰§è¡Œã€‚")
                    updated, response = await _dispatch_channel_task_internal(
                        task_id=int(updated["id"]),
                        user_id=f"feishu:{sender_open_id or 'user'}",
                        session_id=session_id,
                        use_memory=True,
                        message_override=_extract_dispatch_message(updated),
                    )
                    _try_writeback_goal_task_from_channel_task(updated, response)
                    final_text = (response.get("message", "") or "").strip()
                    pending_approval_count = int((updated.get("result") or {}).get("pending_approval_count") or 0)
                    await _try_send_feishu_chat_reply(
                        chat_id,
                        _format_feishu_task_done(
                            int(updated["id"]),
                            str(updated.get("status") or ""),
                            response.get("tool_calls") or [],
                            final_text,
                            pending_approval_count=pending_approval_count,
                        ),
                    )
                    return {"success": True, "task": updated, "handled": cmd.get("cmd"), "auto_dispatched": True}
                except Exception as dispatch_error:
                    failed = channel_task_queue.mark_status(
                        int(updated["id"]),
                        "failed",
                        result={"error": str(dispatch_error)},
                    )
                    await _try_send_feishu_chat_reply(chat_id, _format_feishu_task_failed(int(updated["id"]), dispatch_error))
                    return {"success": False, "task": failed, "error": str(dispatch_error)}
            return {"success": True, "handled": cmd.get("cmd"), "task": updated}
        if cmd.get("cmd") in {"approve", "deny"}:
            decision = "approved" if cmd.get("cmd") == "approve" else "denied"
            approval_id = _resolve_approval_id(str(cmd.get("approval_id") or ""))
            try:
                record = approval_store.decide_request(
                    approval_id,
                    decision=decision,
                    decided_by=f"feishu:{sender_open_id or 'user'}",
                    note=f"Feishu æŒ‡ä»¤: {text[:120]}",
                )
                operator = f"feishu:{sender_open_id or 'user'}"
                await _try_send_feishu_chat_reply(
                    chat_id,
                    "\n".join(
                        [
                            "ã€å®¡æ‰¹æ›´æ–°ã€‘",
                            f"- å®¡æ‰¹ID: {approval_id}",
                            f"- çŠ¶æ€: {record.get('status')}",
                            f"- æ“ä½œäºº: {operator}",
                        ]
                    ),
                )
                send_cards = bool(feishu_runtime_config.get("enable_approval_card", True))
                if send_cards and feishu_adapter.configured:
                    try:
                        await feishu_adapter.send_interactive(
                            receive_id=chat_id,
                            receive_id_type="chat_id",
                            card=_build_feishu_approval_result_card(
                                approval_id=approval_id,
                                status=str(record.get("status") or decision),
                                operator=operator,
                                note=f"æ¥æº: {text[:120]}",
                            ),
                        )
                    except Exception as card_error:
                        logger.warning(f"å‘é€ Feishu å®¡æ‰¹ç»“æœå¡ç‰‡å¤±è´¥: {card_error}")
                linked_task = _find_waiting_approval_task_for_record(chat_id=chat_id, approval_record=record)
                if not linked_task:
                    return {"success": True, "handled": cmd.get("cmd"), "record": record}

                linked_task_id = int(linked_task.get("id") or 0)
                if linked_task_id <= 0:
                    return {"success": True, "handled": cmd.get("cmd"), "record": record}

                if decision == "denied":
                    denied_note = str(record.get("note") or "å®¡æ‰¹æ‹’ç»")
                    failed_task = channel_task_queue.mark_status(
                        linked_task_id,
                        "failed",
                        result={
                            "error": f"å®¡æ‰¹æ‹’ç»ï¼Œä»»åŠ¡ç»ˆæ­¢ï¼š{denied_note}",
                            "approval_id": approval_id,
                            "approval_status": "denied",
                            "session_id": str((linked_task.get("result") or {}).get("session_id") or ""),
                        },
                    )
                    await _try_send_feishu_chat_reply(
                        chat_id,
                        f"ã€ä»»åŠ¡ç»ˆæ­¢ã€‘#{linked_task_id}\n- åŸå› : å®¡æ‰¹å·²æ‹’ç»\n- è¯´æ˜: å¦‚éœ€ç»§ç»­ï¼Œè¯·è°ƒæ•´éœ€æ±‚åé‡æ–°ä¸‹å‘ã€‚",
                    )
                    return {
                        "success": True,
                        "handled": cmd.get("cmd"),
                        "record": record,
                        "task": failed_task,
                        "auto_followup": "terminated",
                    }

                try:
                    resumed = channel_task_queue.mark_status(linked_task_id, "pending")
                    session_id = str((record.get("payload") or {}).get("session_id") or "").strip()
                    if not session_id:
                        session_id = str((linked_task.get("result") or {}).get("session_id") or "").strip()
                    if not session_id:
                        session_id = f"channel:feishu:{chat_id}"
                    dispatch_message = _extract_dispatch_message(linked_task)
                    await _try_send_feishu_chat_reply(
                        chat_id,
                        f"ã€å®¡æ‰¹åç»­è·‘ã€‘#{linked_task_id}\n- çŠ¶æ€: å·²æ¢å¤æ‰§è¡Œ\n- ä¼šè¯: {session_id}",
                    )
                    resumed, resumed_response = await _dispatch_channel_task_internal(
                        task_id=linked_task_id,
                        user_id=f"feishu:{sender_open_id or 'user'}",
                        session_id=session_id,
                        use_memory=True,
                        message_override=dispatch_message,
                    )
                    _try_writeback_goal_task_from_channel_task(resumed, resumed_response)
                    final_text = (resumed_response.get("message", "") or "").strip()
                    pending_approval_count = int((resumed.get("result") or {}).get("pending_approval_count") or 0)
                    await _try_send_feishu_chat_reply(
                        chat_id,
                        _format_feishu_task_done(
                            linked_task_id,
                            str(resumed.get("status") or ""),
                            resumed_response.get("tool_calls") or [],
                            final_text,
                            pending_approval_count=pending_approval_count,
                        ),
                    )
                    return {
                        "success": True,
                        "handled": cmd.get("cmd"),
                        "record": record,
                        "task": resumed,
                        "auto_followup": "resumed",
                    }
                except Exception as follow_error:
                    failed_task = channel_task_queue.mark_status(
                        linked_task_id,
                        "failed",
                        result={"error": f"å®¡æ‰¹é€šè¿‡åè‡ªåŠ¨ç»­è·‘å¤±è´¥: {str(follow_error)}"},
                    )
                    await _try_send_feishu_chat_reply(
                        chat_id,
                        f"ã€ç»­è·‘å¤±è´¥ã€‘#{linked_task_id}\n- é”™è¯¯: {str(follow_error)}\n- å»ºè®®: å¯åœ¨æ¡Œé¢ç«¯ç‚¹å‡»â€œæ¥ç®¡åˆ°å·¥ä½œå°â€æ‰‹åŠ¨å¤„ç†ã€‚",
                    )
                    return {
                        "success": False,
                        "handled": cmd.get("cmd"),
                        "record": record,
                        "task": failed_task,
                        "error": str(follow_error),
                    }
            except Exception as approval_error:
                existing = approval_store.get_request(approval_id) if approval_id else None
                if existing:
                    status = str(existing.get("status") or "unknown")
                    decided_by = str(existing.get("decided_by") or "system")
                    await _try_send_feishu_chat_reply(
                        chat_id,
                        "\n".join(
                            [
                                "ã€å®¡æ‰¹æç¤ºã€‘è¯¥å®¡æ‰¹å·²è¢«å¤„ç†ï¼Œæ— éœ€é‡å¤æ“ä½œã€‚",
                                f"- å®¡æ‰¹ID: {approval_id}",
                                f"- å½“å‰çŠ¶æ€: {status}",
                                f"- å¤„ç†äºº: {decided_by}",
                            ]
                        ),
                    )
                    send_cards = bool(feishu_runtime_config.get("enable_approval_card", True))
                    if send_cards and feishu_adapter.configured:
                        try:
                            await feishu_adapter.send_interactive(
                                receive_id=chat_id,
                                receive_id_type="chat_id",
                                card=_build_feishu_notice_card(
                                    title="å®¡æ‰¹å·²å¤„ç†",
                                    body_lines=[
                                        f"**å®¡æ‰¹ID**: `{approval_id}`",
                                        f"**çŠ¶æ€**: `{status}`",
                                        f"**å¤„ç†äºº**: `{decided_by}`",
                                        "**è¯´æ˜**: è¯¥å®¡æ‰¹å·²å®Œæˆå¤„ç†ï¼Œä½ å¯ä»¥æ‰§è¡Œ `/cks approvals` æŸ¥çœ‹æœ€æ–°é˜Ÿåˆ—ã€‚",
                                    ],
                                    template="grey",
                                ),
                            )
                        except Exception as card_error:
                            logger.warning(f"å‘é€ Feishu å†²çªæç¤ºå¡ç‰‡å¤±è´¥: {card_error}")
                    return {"success": True, "handled": "already-decided", "record": existing}

                await _try_send_feishu_chat_reply(chat_id, f"å®¡æ‰¹å¤±è´¥ï¼š{approval_error}")
                send_cards = bool(feishu_runtime_config.get("enable_approval_card", True))
                if send_cards and feishu_adapter.configured:
                    try:
                        await feishu_adapter.send_interactive(
                            receive_id=chat_id,
                            receive_id_type="chat_id",
                            card=_build_feishu_notice_card(
                                title="å®¡æ‰¹å¤±è´¥",
                                body_lines=[
                                    f"**å®¡æ‰¹ID**: `{approval_id or 'unknown'}`",
                                    f"**é”™è¯¯**: {str(approval_error)[:240]}",
                                    "**å»ºè®®**: ä½¿ç”¨ `/cks approvals` åˆ·æ–°çŠ¶æ€åé‡è¯•ã€‚",
                                ],
                                template="red",
                            ),
                        )
                    except Exception as card_error:
                        logger.warning(f"å‘é€ Feishu å¤±è´¥æç¤ºå¡ç‰‡å¤±è´¥: {card_error}")
                return {"success": False, "error": str(approval_error)}

        task = channel_task_queue.enqueue(
            channel="feishu",
            external_id=external_id,
            sender_id=sender_open_id or "unknown",
            chat_id=chat_id,
            message=text,
            metadata={
                "raw_event_type": payload.get("header", {}).get("event_type", ""),
                "event_id": event_id,
                "message_id": message_id,
                "raw": payload,
                "receive_id": chat_id,
                "receive_id_type": "chat_id",
                **({"goal_task_id": cmd.get("goal_task_id")} if cmd.get("cmd") == "task" else {}),
            },
        )
        auto_dispatch = bool(feishu_runtime_config.get("auto_dispatch", True))
        if cmd.get("cmd") in {"run", "task", "desktop"}:
            auto_dispatch = True
        if auto_dispatch:
            if cmd.get("cmd") == "desktop" and cmd.get("prompt"):
                dispatch_message = (
                    "è¯·ä¼˜å…ˆä½¿ç”¨æ¡Œé¢å·¥å…·é“¾å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼Œå¹¶å›æŠ¥å¯éªŒè¯äº§ç‰©è·¯å¾„ï¼š\n"
                    f"{cmd.get('prompt')}"
                )
            elif cmd.get("cmd") == "run" and cmd.get("prompt"):
                dispatch_message = str(cmd.get("prompt"))
            else:
                dispatch_message = text
            try:
                session_id = f"channel:feishu:{chat_id}"
                await _try_send_feishu_chat_reply(
                    chat_id,
                    _format_feishu_task_started(task["id"], session_id, dispatch_message),
                )
                await _try_send_feishu_chat_reply(chat_id, f"ã€è¿›åº¦ã€‘#{task['id']} é˜¶æ®µ2/3ï¼šæ­£åœ¨è°ƒç”¨ Agent ä¸å·¥å…·é“¾â€¦")
                updated, response = await _dispatch_channel_task_internal(
                    task_id=task["id"],
                    user_id=f"feishu:{sender_open_id or 'user'}",
                    session_id=session_id,
                    use_memory=True,
                    message_override=dispatch_message,
                )
                _try_writeback_goal_task_from_channel_task(updated, response)
                tool_calls = response.get("tool_calls") or []
                final_text = (response.get("message", "") or "").strip()
                pending_approval_count = int((updated.get("result") or {}).get("pending_approval_count") or 0)
                await _try_send_feishu_chat_reply(chat_id, "ã€è¿›åº¦ã€‘é˜¶æ®µ3/3ï¼šæ‰§è¡Œç»“æœå·²å›å†™ï¼Œå‡†å¤‡å›æ‰§ã€‚")
                await _try_send_feishu_chat_reply(
                    chat_id,
                    _format_feishu_task_done(
                        task["id"],
                        str(updated.get("status") or ""),
                        tool_calls,
                        final_text,
                        pending_approval_count=pending_approval_count,
                    ),
                )
                return {"success": True, "task": updated, "auto_dispatched": True}
            except Exception as dispatch_error:
                failed = channel_task_queue.mark_status(
                    task["id"],
                    "failed",
                    result={"error": str(dispatch_error)},
                )
                await _try_send_feishu_chat_reply(chat_id, _format_feishu_task_failed(task["id"], dispatch_error))
                return {"success": False, "task": failed, "error": str(dispatch_error)}

        await _try_send_feishu_chat_reply(chat_id, f"å·²æ¥æ”¶ä»»åŠ¡ #{task['id']}ï¼Œç¨åæ‰§è¡Œã€‚")
        return {"success": True, "task": task, "queued": True}
    except Exception as e:
        logger.error(f"Feishu events å¤„ç†å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/channels/feishu/outbound")
async def feishu_outbound(request: FeishuOutboundRequest):
    """å‘é€æ–‡æœ¬æ¶ˆæ¯åˆ° Feishuï¼ˆMVPï¼‰"""
    try:
        if not feishu_adapter.configured:
            return {"success": False, "error": "Feishu adapter not configured (FEISHU_APP_ID/SECRET missing)"}
        result = await feishu_adapter.send_text(
            receive_id=request.receive_id,
            text=request.text,
            receive_id_type=request.receive_id_type,
        )
        return result
    except Exception as e:
        logger.error(f"Feishu outbound å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/channels/feishu/config")
async def get_feishu_config():
    """è·å–å½“å‰é£ä¹¦æœºå™¨äººé…ç½®ï¼ˆæ•æ„Ÿå­—æ®µè„±æ•ï¼‰"""
    return {
        "success": True,
        "config": _redact_feishu_config(feishu_runtime_config),
        "configured": bool(feishu_adapter.configured),
    }


@app.post("/channels/feishu/config")
async def update_feishu_config(request: FeishuConfigUpdateRequest):
    """æ›´æ–°é£ä¹¦æœºå™¨äººé…ç½®å¹¶æŒä¹…åŒ–åˆ° data/feishu_config.json"""
    try:
        next_config = {
            "app_id": request.app_id.strip(),
            "app_secret": _resolve_secret_field("app_secret", request.app_secret),
            "verification_token": _resolve_secret_field("verification_token", request.verification_token),
            "encrypt_key": _resolve_secret_field("encrypt_key", request.encrypt_key),
            "domain": (request.domain.strip().lower() or "feishu"),
            "auto_dispatch": bool(request.auto_dispatch),
            "enable_approval_card": bool(request.enable_approval_card),
            "allowed_senders": request.allowed_senders.strip(),
            "signature_tolerance_sec": max(0, int(request.signature_tolerance_sec)),
            "replay_cache_size": max(32, int(request.replay_cache_size)),
        }
        _save_feishu_config(next_config)
        _apply_feishu_runtime_config(next_config)
        return {
            "success": True,
            "config": _redact_feishu_config(feishu_runtime_config),
            "configured": bool(feishu_adapter.configured),
        }
    except Exception as e:
        logger.error(f"æ›´æ–°é£ä¹¦é…ç½®å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/channels/feishu/config/test")
async def test_feishu_config(request: FeishuConfigTestRequest):
    """æµ‹è¯•é£ä¹¦é…ç½®è¿é€šæ€§ï¼Œå¯é€‰å‘é€æ¢æµ‹æ¶ˆæ¯ã€‚"""
    try:
        if not feishu_adapter.configured:
            return {"success": False, "error": "é£ä¹¦é…ç½®ä¸å®Œæ•´ï¼šç¼ºå°‘ app_id æˆ– app_secret"}
        token = await feishu_adapter._get_tenant_access_token()
        result = {"success": True, "token_ok": bool(token)}
        if request.send_probe:
            if not request.receive_id.strip():
                return {"success": False, "error": "å‘é€æ¢æµ‹æ¶ˆæ¯æ—¶å¿…é¡»æä¾› receive_id"}
            send_result = await feishu_adapter.send_text(
                receive_id=request.receive_id.strip(),
                receive_id_type=request.receive_id_type.strip() or "chat_id",
                text=request.text.strip() or "CKS é£ä¹¦è¿é€šæ€§æµ‹è¯•æˆåŠŸ",
            )
            result["probe"] = send_result
            result["success"] = bool(send_result.get("success"))
        return result
    except Exception as e:
        logger.error(f"æµ‹è¯•é£ä¹¦é…ç½®å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/channels/feishu/config/diagnose")
async def diagnose_feishu_config(request: Request, include_probe: int = 1, public_base_url: str = ""):
    """ä¸€é”®è¯Šæ–­é£ä¹¦æœºå™¨äººé…ç½®ï¼Œå¹¶è¿”å›å»ºè®®çš„å›è°ƒåœ°å€ã€‚"""
    try:
        base_url = (
            (public_base_url or "").strip()
            or os.getenv("CKS_PUBLIC_API_BASE_URL", "").strip()
            or str(request.base_url).rstrip("/")
        )
        callback_urls = _build_feishu_callback_urls(base_url)
        checks = _build_feishu_diagnostic_checks(callback_urls)

        probe_ok = False
        if include_probe and feishu_adapter.configured:
            try:
                token = await feishu_adapter._get_tenant_access_token()
                probe_ok = bool(token)
                checks.append({
                    "id": "token_probe",
                    "title": "é‰´æƒè¿é€šæ€§",
                    "status": "pass" if probe_ok else "fail",
                    "detail": "tenant_access_token è·å–æˆåŠŸã€‚" if probe_ok else "æ— æ³•è·å– tenant_access_tokenã€‚",
                    "action": "" if probe_ok else "æ£€æŸ¥ App ID / App Secret æ˜¯å¦æ­£ç¡®ï¼Œç¡®è®¤åº”ç”¨å·²å‘å¸ƒå¹¶å¼€é€šæœºå™¨äººæƒé™ã€‚",
                })
            except Exception as e:
                checks.append({
                    "id": "token_probe",
                    "title": "é‰´æƒè¿é€šæ€§",
                    "status": "fail",
                    "detail": f"é‰´æƒå¤±è´¥ï¼š{e}",
                    "action": "æ£€æŸ¥åº”ç”¨å‡­æ®ã€é£ä¹¦å¼€æ”¾å¹³å°æƒé™ä¸ç½‘ç»œè¿é€šæ€§ã€‚",
                })

        return {
            "success": True,
            "configured": bool(feishu_adapter.configured),
            "probe_ok": probe_ok if include_probe else None,
            "checks": checks,
            "callback_urls": callback_urls,
        }
    except Exception as e:
        logger.error(f"è¯Šæ–­é£ä¹¦é…ç½®å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/channels/feishu/commands")
async def feishu_commands():
    """è¿”å› Feishu æœºå™¨äººæ”¯æŒçš„å‘½ä»¤åˆ—è¡¨ï¼ˆç”¨äºå‰ç«¯æç¤º/æ–‡æ¡£ï¼‰"""
    return {
        "success": True,
        "commands": [
            {"cmd": "/cks status", "description": "æŸ¥çœ‹ä»»åŠ¡ä¸å®¡æ‰¹çŠ¶æ€"},
            {"cmd": "approve <å®¡æ‰¹ID>", "description": "æ‰¹å‡†æŒ‡å®šå®¡æ‰¹ï¼ˆæ”¯æŒçŸ­IDå‰ç¼€ï¼‰"},
            {"cmd": "deny <å®¡æ‰¹ID>", "description": "æ‹’ç»æŒ‡å®šå®¡æ‰¹ï¼ˆæ”¯æŒçŸ­IDå‰ç¼€ï¼‰"},
            {"cmd": "run <ä»»åŠ¡æè¿°>", "description": "æ™®é€šè‡ªåŠ¨æ‰§è¡Œ"},
            {"cmd": "desktop <ä»»åŠ¡æè¿°>", "description": "æ¡Œé¢å·¥å…·ä¼˜å…ˆæ‰§è¡Œ"},
            {"cmd": "computer <ä»»åŠ¡æè¿°>", "description": "desktop çš„åŒä¹‰å‘½ä»¤"},
            {"cmd": "task <ä»»åŠ¡ID>", "description": "ç»‘å®š Goal ä»»åŠ¡å¹¶æ‰§è¡Œ"},
        ],
    }


@app.post("/channels/feishu/inbound")
async def feishu_inbound(request: ChannelInboundMessageRequest):
    """Feishu å…¥ç«™æ¶ˆæ¯å…¥å£ï¼ˆè°ƒè¯•/MVP æ‰‹å·¥æ³¨å…¥ï¼‰ã€‚"""
    try:
        metadata = request.metadata if isinstance(request.metadata, dict) else {}
        external_id = str(
            metadata.get("external_id")
            or metadata.get("event_id")
            or metadata.get("message_id")
            or ""
        ).strip()
        item = channel_task_queue.enqueue(
            channel=request.channel or "feishu",
            external_id=external_id,
            sender_id=request.sender_id,
            chat_id=request.chat_id,
            message=request.message,
            metadata=metadata,
        )
        if request.auto_dispatch:
            dispatch_session_id = f"channel:{item['channel']}:{item['chat_id']}"
            try:
                node_hint = _resolve_channel_task_execution_node(item)
                item, response = await _dispatch_channel_task_internal(
                    task_id=item["id"],
                    user_id=request.user_id,
                    session_id=dispatch_session_id,
                    use_memory=True,
                    execution_node_id=node_hint,
                )
                _try_writeback_goal_task_from_channel_task(item, response)
                if feishu_adapter.configured:
                    receive_id = (item.get("metadata") or {}).get("receive_id") or request.sender_id
                    receive_id_type = (item.get("metadata") or {}).get("receive_id_type") or "open_id"
                    await _try_send_feishu_chat_reply(
                        str(receive_id),
                        response.get("message", "") or "ä»»åŠ¡å·²æ‰§è¡Œå®Œæˆã€‚",
                        str(receive_id_type),
                    )
            except Exception as dispatch_error:
                item = channel_task_queue.mark_status(
                    item["id"],
                    "failed",
                    result={"error": str(dispatch_error)},
                )
        return {"success": True, "task": item}
    except Exception as e:
        logger.error(f"Feishu å…¥ç«™å¤„ç†å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/channels/tasks")
async def list_channel_tasks(channel: str = "", status: str = "", limit: int = 50):
    """æŸ¥è¯¢æ¸ é“ä»»åŠ¡é˜Ÿåˆ—ï¼ˆé£ä¹¦/ä¼ä¸šå¾®ä¿¡/é’‰é’‰åç»­å¤ç”¨ï¼‰"""
    try:
        normalized_status = _normalize_channel_status(status)
        rows = channel_task_queue.list(
            channel=channel.strip() or None,
            status=normalized_status or None,
            limit=limit,
        )
        return {"success": True, "tasks": rows, "total": len(rows)}
    except Exception as e:
        logger.error(f"æŸ¥è¯¢æ¸ é“ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/channels/tasks/{task_id}/dispatch")
async def dispatch_channel_task(task_id: int, request: ChannelTaskDispatchRequest):
    """æ‰‹åŠ¨æ´¾å‘æ¸ é“ä»»åŠ¡åˆ° Agentï¼ˆç”¨äºè€æ¿çœ‹æ¿/é£ä¹¦ä»»åŠ¡ï¼‰"""
    try:
        task = channel_task_queue.get(task_id)
        if not task:
            return {"success": False, "error": f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}"}

        task_status = _normalize_channel_status(str(task.get("status") or ""))
        if task_status == "running":
            return {"success": False, "error": "ä»»åŠ¡æ­£åœ¨æ‰§è¡Œä¸­"}
        if task_status in {"completed", "failed", "canceled"}:
            return {"success": False, "error": f"ä»»åŠ¡å·²ç»“æŸï¼ˆ{task_status}ï¼‰ï¼Œæ— æ³•å†æ¬¡æ´¾å‘"}

        session_id = request.session_id or f"channel:{task['channel']}:{task['chat_id']}"
        try:
            node_hint = _resolve_channel_task_execution_node(task, request.node_id or "")
            task, response = await _dispatch_channel_task_internal(
                task_id=task_id,
                user_id=request.user_id,
                session_id=session_id,
                use_memory=request.use_memory,
                execution_node_id=node_hint,
            )
            _try_writeback_goal_task_from_channel_task(task, response)
            if task.get("channel") == "feishu" and feishu_adapter.configured:
                receive_id = task.get("sender_id") or ""
                if receive_id:
                    receive_id_type = (task.get("metadata") or {}).get("receive_id_type") or "open_id"
                    await _try_send_feishu_chat_reply(
                        str(receive_id),
                        response.get("message", "") or "ä»»åŠ¡å·²æ‰§è¡Œå®Œæˆã€‚",
                        str(receive_id_type),
                    )
            return {"success": True, "task": task}
        except Exception as dispatch_error:
            task = channel_task_queue.mark_status(
                task_id,
                "failed",
                result={"error": str(dispatch_error)},
            )
            return {"success": False, "error": str(dispatch_error), "task": task}
    except Exception as e:
        logger.error(f"æ´¾å‘æ¸ é“ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/channels/tasks/{task_id}/control")
async def control_channel_task(task_id: int, action: str):
    """æ§åˆ¶æ¸ é“ä»»åŠ¡çŠ¶æ€ï¼špause | resume | cancel | retry"""
    try:
        normalized_action = (action or "").strip().lower()
        if normalized_action not in {"pause", "resume", "cancel", "retry"}:
            return {"success": False, "error": f"ä¸æ”¯æŒçš„åŠ¨ä½œ: {normalized_action}"}

        task = channel_task_queue.get(task_id)
        if not task:
            return {"success": False, "error": f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}"}

        if normalized_action == "retry":
            updated, tip = _prepare_retry_channel_task(task)
        else:
            updated, tip = _control_channel_task(task, normalized_action)
        return {"success": True, "task": updated or task, "message": tip}
    except Exception as e:
        logger.error(f"æ§åˆ¶æ¸ é“ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/search")
async def web_search(
    query: str,
    num_results: int = 5,
    site: str = None,
    time_range: str = None
):
    """è”ç½‘æœç´¢ (UAPI)"""
    try:
        response = await agent.web_search.search(
            query=query,
            num_results=num_results,
            site=site,
            time_range=time_range
        )

        return {
            "success": response.success,
            "results": [
                {
                    "title": r.title,
                    "url": r.url,
                    "snippet": r.snippet,
                    "content": r.content
                }
                for r in response.results
            ],
            "provider": response.provider,
            "error": response.error
        }
    except Exception as e:
        logger.error(f"è”ç½‘æœç´¢é”™è¯¯: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/goals/tree")
async def get_goals_tree(organization_id: str = None):
    """è·å– KPI/OKR/é¡¹ç›®/ä»»åŠ¡æ ‘"""
    try:
        return {"success": True, "data": goal_manager.get_tree(organization_id=organization_id)}
    except Exception as e:
        logger.error(f"è·å– goals tree å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/goals/tasks")
async def list_goal_tasks(
    organization_id: str = None,
    task_id: int = None,
    assignee: str = None,
    department: str = None,
    status: str = None,
    review_status: str = None,
    handoff_status: str = None,
    handoff_owner: str = None,
    from_time: str = None,
    to_time: str = None,
    limit: int = 200,
):
    try:
        rows = goal_manager.list_tasks(
            organization_id=organization_id,
            task_id=task_id,
            assignee=assignee,
            department=department,
            status=status,
            review_status=review_status,
            handoff_status=handoff_status,
            handoff_owner=handoff_owner,
            from_time=from_time,
            to_time=to_time,
            limit=limit,
        )
        return {"success": True, "tasks": rows, "total": len(rows)}
    except Exception as e:
        logger.error(f"List goals tasks failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/goals/dashboard")
async def get_goals_dashboard(
    organization_id: str = None,
    from_time: str = None,
    to_time: str = None,
    limit: int = 2000,
):
    try:
        data = goal_manager.get_dashboard_data(
            organization_id=organization_id,
            from_time=from_time,
            to_time=to_time,
            limit=limit,
        )
        return {"success": True, **data}
    except Exception as e:
        logger.error(f"Get goals dashboard failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/goals/dashboard/next-task")
async def set_goals_dashboard_next_task(request: GoalDashboardNextTaskRequest):
    try:
        ok = goal_manager.set_assignee_next_task(
            assignee=request.assignee,
            task_id=request.task_id,
            organization_id=request.organization_id,
        )
        if not ok:
            return {"success": False, "error": "Task not found for assignee"}
        return {"success": True}
    except Exception as e:
        logger.error(f"Set goals dashboard next task failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/goals/supervisor/dispatch")
async def run_goals_supervisor_dispatch(request: GoalSupervisorDispatchRequest):
    try:
        data = goal_manager.run_supervisor_dispatch(
            organization_id=request.organization_id,
            objective=request.objective,
            max_assignees=request.max_assignees,
            prefer_pending_review=request.prefer_pending_review,
            supervisor_name=request.supervisor_name,
        )
        return {"success": True, **data}
    except Exception as e:
        logger.error(f"Run goals supervisor dispatch failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/goals/supervisor/review")
async def run_goals_supervisor_review(request: GoalSupervisorReviewRequest):
    try:
        data = goal_manager.run_supervisor_review(
            organization_id=request.organization_id,
            window_days=request.window_days,
            supervisor_name=request.supervisor_name,
        )
        return {"success": True, **data}
    except Exception as e:
        logger.error(f"Run goals supervisor review failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/goals/ai-employees")
async def list_goals_ai_employees(organization_id: str = None):
    try:
        items = goal_manager.list_ai_employees(organization_id=organization_id)
        return {"success": True, "items": items, "total": len(items)}
    except Exception as e:
        logger.error(f"List AI employees failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/goals/ai-employees/upsert")
async def upsert_goals_ai_employee(request: AiEmployeeUpsertRequest):
    try:
        ok = goal_manager.upsert_ai_employee(
            name=request.name,
            role=request.role,
            specialty=request.specialty,
            primary_skill=request.primary_skill,
            skill_stack=request.skill_stack,
            status=request.status,
            organization_id=request.organization_id,
        )
        if not ok:
            return {"success": False, "error": "Invalid employee payload"}
        return {"success": True}
    except Exception as e:
        logger.error(f"Upsert AI employee failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/goals/ai-employees/delete")
async def delete_goals_ai_employee(request: AiEmployeeDeleteRequest):
    try:
        ok = goal_manager.delete_ai_employee(name=request.name, organization_id=request.organization_id)
        if not ok:
            return {"success": False, "error": "Employee not found"}
        return {"success": True}
    except Exception as e:
        logger.error(f"Delete AI employee failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/goals/skill-presets")
async def list_goals_skill_presets(organization_id: str = None):
    try:
        items = goal_manager.list_skill_presets(organization_id=organization_id)
        return {"success": True, "items": items, "total": len(items)}
    except Exception as e:
        logger.error(f"List skill presets failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/goals/skill-presets/upsert")
async def upsert_goals_skill_preset(request: AiSkillPresetUpsertRequest):
    try:
        ok = goal_manager.upsert_skill_preset(
            preset_id=request.id,
            name=request.name,
            primary_skill=request.primary_skill,
            skills=request.skills,
            organization_id=request.organization_id,
        )
        if not ok:
            return {"success": False, "error": "Invalid skill preset payload"}
        return {"success": True}
    except Exception as e:
        logger.error(f"Upsert skill preset failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/goals/skill-presets/delete")
async def delete_goals_skill_preset(request: AiSkillPresetDeleteRequest):
    try:
        ok = goal_manager.delete_skill_preset(preset_id=request.id, organization_id=request.organization_id)
        if not ok:
            return {"success": False, "error": "Skill preset not found"}
        return {"success": True}
    except Exception as e:
        logger.error(f"Delete skill preset failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/goals/bootstrap/demo")
async def bootstrap_goals_demo(request: GoalDemoBootstrapRequest):
    try:
        data = goal_manager.bootstrap_one_person_company_demo(
            organization_id=request.organization_id,
            owner_name=request.owner_name,
            reset_existing=request.reset_existing,
        )
        return {"success": True, **data}
    except Exception as e:
        logger.error(f"Bootstrap goals demo failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/goals/kpi")
async def create_kpi(request: GoalKPIRequest):
    try:
        kpi_id = goal_manager.create_kpi(request.title, request.description, organization_id=request.organization_id)
        return {"success": True, "id": kpi_id}
    except Exception as e:
        logger.error(f"åˆ›å»º KPI å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/goals/okr")
async def create_okr(request: GoalOKRRequest):
    try:
        okr_id = goal_manager.create_okr(request.kpi_id, request.title, request.description)
        return {"success": True, "id": okr_id}
    except Exception as e:
        logger.error(f"åˆ›å»º OKR å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/goals/project")
async def create_project(request: GoalProjectRequest):
    try:
        project_id = goal_manager.create_project(request.okr_id, request.title, request.description)
        return {"success": True, "id": project_id}
    except Exception as e:
        logger.error(f"åˆ›å»ºé¡¹ç›®å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/goals/task")
async def create_task(request: GoalTaskRequest):
    try:
        task_id = goal_manager.create_task(
            project_id=request.project_id,
            title=request.title,
            description=request.description,
            assignee=request.assignee,
            department=request.department,
        )
        return {"success": True, "id": task_id}
    except Exception as e:
        logger.error(f"åˆ›å»ºä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.delete("/goals/task/{task_id}")
async def delete_task(task_id: int):
    try:
        ok = goal_manager.delete_task(task_id)
        if not ok:
            return {"success": False, "error": "Task not found"}
        return {"success": True}
    except Exception as e:
        logger.error(f"Delete task failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.delete("/goals/project/{project_id}")
async def delete_project(project_id: int):
    try:
        ok = goal_manager.delete_project(project_id)
        if not ok:
            return {"success": False, "error": "Project not found"}
        return {"success": True}
    except Exception as e:
        logger.error(f"Delete project failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.delete("/goals/okr/{okr_id}")
async def delete_okr(okr_id: int):
    try:
        ok = goal_manager.delete_okr(okr_id)
        if not ok:
            return {"success": False, "error": "OKR not found"}
        return {"success": True}
    except Exception as e:
        logger.error(f"Delete okr failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.delete("/goals/kpi/{kpi_id}")
async def delete_kpi(kpi_id: int):
    try:
        ok = goal_manager.delete_kpi(kpi_id)
        if not ok:
            return {"success": False, "error": "KPI not found"}
        return {"success": True}
    except Exception as e:
        logger.error(f"Delete kpi failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/goals/task/{task_id}/complete")
async def complete_task(task_id: int):
    try:
        ok = goal_manager.complete_task(task_id)
        if not ok:
            return {"success": False, "error": "Task not found"}
        return {"success": True}
    except Exception as e:
        logger.error(f"å®Œæˆä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/goals/task/{task_id}/review")
async def review_task(task_id: int, request: GoalTaskReviewRequest):
    try:
        ok = goal_manager.review_task(
            task_id=task_id,
            decision=request.decision,
            reason=request.reason,
            reviewed_by=request.reviewed_by,
        )
        if not ok:
            return {"success": False, "error": "Task not found or invalid decision"}

        try:
            if agent.audit_logger:
                if request.decision == "reject":
                    agent.audit_logger.log_error(
                        user_id=request.reviewed_by or "manager",
                        session_id=f"goals-review-{task_id}",
                        tool_name="goal_task_review",
                        tool_input={"task_id": task_id, "decision": request.decision, "reason": request.reason},
                        error=request.reason or "Task rejected by reviewer",
                        duration_ms=0,
                        goal_task_id=task_id,
                    )
                else:
                    agent.audit_logger.log_execution(
                        user_id=request.reviewed_by or "manager",
                        session_id=f"goals-review-{task_id}",
                        tool_name="goal_task_review",
                        tool_input={"task_id": task_id, "decision": request.decision, "reason": request.reason},
                        success=True,
                        duration_ms=0,
                        message=request.reason or "Task accepted by reviewer",
                        goal_task_id=task_id,
                    )
        except Exception as audit_error:
            logger.warning(f"Failed to write task review audit log: {audit_error}")

        return {"success": True}
    except Exception as e:
        logger.error(f"Review task failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/goals/task/{task_id}/handoff/claim")
async def claim_goal_task_handoff(task_id: int, request: GoalTaskHandoffClaimRequest):
    try:
        ok = goal_manager.claim_task_handoff(
            task_id=task_id,
            owner=request.owner,
            note=request.note,
        )
        if not ok:
            return {"success": False, "error": "Task not found, not rejected, or invalid owner"}
        return {"success": True}
    except Exception as e:
        logger.error(f"Claim task handoff failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/goals/task/{task_id}/execution/state")
async def get_goal_task_execution_state(task_id: int):
    try:
        data = goal_manager.get_execution_state(task_id)
        if not data:
            return {"success": False, "error": "Task not found"}
        return {"success": True, "data": data}
    except Exception as e:
        logger.error(f"Get task execution state failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/goals/task/{task_id}/execution/events")
async def get_goal_task_execution_events(task_id: int, limit: int = 50):
    try:
        records = goal_manager.list_execution_events(task_id=task_id, limit=limit)
        if records is None:
            return {"success": False, "error": "Task not found"}
        return {"success": True, "records": records, "total": len(records)}
    except Exception as e:
        logger.error(f"Get task execution events failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/goals/task/{task_id}/execution/phase")
async def update_goal_task_execution_phase(task_id: int, request: GoalTaskExecutionPhaseRequest):
    try:
        data = goal_manager.update_execution_phase(
            task_id=task_id,
            phase=request.phase,
            status=request.status,
            note=request.note,
            prompt=request.prompt,
        )
        if not data:
            return {"success": False, "error": "Task not found or invalid phase/status"}
        return {"success": True, "data": data}
    except Exception as e:
        logger.error(f"Update task execution phase failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/goals/task/{task_id}/execution/resume")
async def resume_goal_task_execution(task_id: int, request: GoalTaskExecutionResumeRequest):
    try:
        data = goal_manager.resume_execution(task_id=task_id, note=request.note)
        if not data:
            return {"success": False, "error": "Task not found"}
        resume_prompt = data.pop("resume_prompt", "")
        return {"success": True, "data": data, "resume_prompt": resume_prompt}
    except Exception as e:
        logger.error(f"Resume task execution failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/goals/task/{task_id}/execution/readiness")
async def get_goal_task_execution_readiness(task_id: int, organization_id: str = None):
    try:
        tasks = goal_manager.list_tasks(organization_id=organization_id, task_id=task_id, limit=1)
        task = tasks[0] if tasks else None
        if not task:
            return {"success": False, "error": "Task not found"}

        execution_state = goal_manager.get_execution_state(task_id) or {}
        executions = _read_audit_records("execution", goal_task_id=task_id, limit=20)
        errors = _read_audit_records("error", goal_task_id=task_id, limit=20)
        has_execution = len(executions) > 0
        note = str(execution_state.get("note") or "").strip()
        prompt = str(execution_state.get("last_prompt") or "").strip()
        has_context = bool(note or prompt)
        task_status = (task.get("status") or "").strip().lower()
        review_status = (task.get("review_status") or "").strip().lower()
        is_already_done = task_status == "done" and review_status in {"pending", "accepted"}

        checks = [
            {"key": "has_execution_traces", "ok": has_execution, "detail": f"audit executions={len(executions)}"},
            {"key": "has_execution_context", "ok": has_context, "detail": "execution note/prompt present"},
            {"key": "not_blocked_by_recent_errors", "ok": len(errors) == 0, "detail": f"audit errors={len(errors)}"},
            {"key": "task_not_already_done", "ok": not is_already_done, "detail": f"task status={task_status}/{review_status or 'pending'}"},
        ]
        can_complete = all(item["ok"] for item in checks[:2]) and checks[2]["ok"]
        return {
            "success": True,
            "data": {
                "task_id": task_id,
                "can_complete": bool(can_complete),
                "checks": checks,
                "execution_count": len(executions),
                "error_count": len(errors),
            },
        }
    except Exception as e:
        logger.error(f"Get task execution readiness failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/goals/task/{task_id}/subagent-runs/spawn")
async def spawn_goal_task_subagent_run(task_id: int, request: GoalTaskSubagentSpawnRequest):
    try:
        task_rows = goal_manager.list_tasks(
            organization_id=request.organization_id,
            task_id=task_id,
            limit=1,
        )
        if not task_rows:
            return {"success": False, "error": "Task not found"}
        task_row = task_rows[0]
        normalized_org = str(task_row.get("organization_id") or "default-org").strip() or "default-org"
        run_id = f"run-{uuid4().hex[:12]}"
        created = goal_manager.create_subagent_run(
            run_id=run_id,
            task_id=task_id,
            organization_id=normalized_org,
            assignee=str(task_row.get("assignee") or ""),
            supervisor_name=request.supervisor_name,
            objective=request.objective,
            node_id=request.node_id,
            parent_session_id=request.session_id,
            metadata={
                "auto_complete": bool(request.auto_complete),
            },
        )
        if not created:
            return {"success": False, "error": "Failed to create subagent run"}
        runtime_task = asyncio.create_task(
            _run_subagent_task_async(
                run_id=run_id,
                task_id=task_id,
                organization_id=normalized_org,
                objective=request.objective,
                supervisor_name=request.supervisor_name,
                auto_complete=bool(request.auto_complete),
            )
        )
        subagent_runtime_tasks[run_id] = runtime_task
        return {"success": True, "run": created}
    except Exception as e:
        logger.error(f"Spawn task subagent run failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/goals/task/{task_id}/subagent-runs")
async def list_goal_task_subagent_runs(task_id: int, organization_id: str = None, limit: int = 30):
    try:
        task_rows = goal_manager.list_tasks(
            organization_id=organization_id,
            task_id=task_id,
            limit=1,
        )
        if not task_rows:
            return {"success": False, "error": "Task not found", "items": []}
        normalized_org = str(task_rows[0].get("organization_id") or "default-org").strip() or "default-org"
        rows = goal_manager.list_subagent_runs(
            organization_id=normalized_org,
            task_id=task_id,
            limit=limit,
        )
        return {"success": True, "items": rows, "total": len(rows)}
    except Exception as e:
        logger.error(f"List task subagent runs failed: {e}", exc_info=True)
        return {"success": False, "error": str(e), "items": []}


@app.get("/goals/subagent-runs/{run_id}")
async def get_goal_subagent_run(run_id: str):
    try:
        data = goal_manager.get_subagent_run(run_id)
        if not data:
            return {"success": False, "error": "Run not found"}
        return {"success": True, "run": data}
    except Exception as e:
        logger.error(f"Get subagent run failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/goals/subagent-runs/{run_id}/events")
async def list_goal_subagent_run_events(run_id: str, limit: int = 120):
    try:
        rows = goal_manager.list_subagent_run_events(run_id=run_id, limit=limit)
        if rows is None:
            return {"success": False, "error": "Run not found", "records": []}
        return {"success": True, "records": rows, "total": len(rows)}
    except Exception as e:
        logger.error(f"List subagent run events failed: {e}", exc_info=True)
        return {"success": False, "error": str(e), "records": []}


@app.post("/goals/subagent-runs/{run_id}/control")
async def control_goal_subagent_run(run_id: str, request: GoalTaskSubagentControlRequest):
    try:
        action = (request.action or "cancel").strip().lower()
        if action != "cancel":
            return {"success": False, "error": "Unsupported action"}
        runtime_task = subagent_runtime_tasks.get(run_id)
        if runtime_task and not runtime_task.done():
            runtime_task.cancel()
        reason = (request.reason or "").strip()
        state = goal_manager.set_subagent_run_status(
            run_id=run_id,
            status="cancelled",
            error_text=reason or "Cancelled by user",
        )
        if not state:
            return {"success": False, "error": "Run not found"}
        goal_manager.append_subagent_run_event(
            run_id=run_id,
            stage="fallback",
            message=f"è¿è¡Œå·²å–æ¶ˆã€‚{reason}" if reason else "è¿è¡Œå·²å–æ¶ˆã€‚",
        )
        return {"success": True, "run": state}
    except Exception as e:
        logger.error(f"Control subagent run failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.get("/goals/task/{task_id}/agent-profile")
async def get_goal_task_agent_profile(task_id: int, organization_id: str = None):
    try:
        data = goal_manager.get_task_agent_profile(task_id=task_id, organization_id=organization_id)
        if not data:
            return {"success": False, "error": "Task agent profile not found"}
        return {"success": True, "data": data}
    except Exception as e:
        logger.error(f"Get goal task agent profile failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.post("/goals/task/{task_id}/agent-profile/upsert")
async def upsert_goal_task_agent_profile(task_id: int, request: GoalTaskAgentProfileUpsertRequest):
    try:
        ok = goal_manager.upsert_task_agent_profile(
            task_id=task_id,
            organization_id=request.organization_id,
            assignee=request.assignee,
            role=request.role,
            specialty=request.specialty,
            preferred_skill=request.preferred_skill,
            skill_stack=request.skill_stack,
            skill_strict=request.skill_strict,
            seed_prompt=request.seed_prompt,
        )
        if not ok:
            return {"success": False, "error": "Task not found or invalid profile payload"}
        data = goal_manager.get_task_agent_profile(task_id=task_id, organization_id=request.organization_id)
        return {"success": True, "data": data}
    except Exception as e:
        logger.error(f"Upsert goal task agent profile failed: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocket è¿æ¥ï¼ˆå®æ—¶å¯¹è¯ï¼‰"""
    await websocket.accept()
    logger.info("WebSocket è¿æ¥å»ºç«‹")

    try:
        while True:
            data = await websocket.receive_json()

            # å¤„ç†æ¶ˆæ¯
            user_id = data.get("user_id")
            message = data.get("message")
            session_id = data.get("session_id")
            goal_task_id = data.get("goal_task_id")
            preferred_skill = data.get("preferred_skill")
            skill_strict = bool(data.get("skill_strict", False))

            # æµå¼å“åº”
            async for chunk in agent.chat_stream(
                user_id=user_id,
                message=message,
                session_id=session_id,
                use_memory=True,
                goal_task_id=goal_task_id,
                preferred_skill=preferred_skill,
                skill_strict=skill_strict,
            ):
                await websocket.send_json(chunk)

            # å‘é€ç»“æŸæ ‡è®°
            await websocket.send_json({"type": "done"})

    except WebSocketDisconnect:
        logger.info("WebSocket è¿æ¥æ–­å¼€")
    except Exception as e:
        logger.error(f"WebSocket é”™è¯¯: {e}", exc_info=True)


def main():
    """å¯åŠ¨æœåŠ¡"""
    host = os.getenv("HOST", "127.0.0.1")
    port = int(os.getenv("PORT", 7860))
    reload = os.getenv("RELOAD", "0") == "1"

    logger.info(f"å¯åŠ¨ Agent SDK æœåŠ¡: http://{host}:{port} (reload={reload})")

    # ç›´æ¥ä¼ å…¥ app å¯¹è±¡ï¼Œé¿å… `main:app` å†æ¬¡å¯¼å…¥æ¨¡å—å¯¼è‡´åˆå§‹åŒ–æ—¥å¿—/è€—æ—¶é‡å¤ã€‚
    if reload:
        uvicorn.run(
            "main:app",
            host=host,
            port=port,
            log_level="info",
            reload=True,
            reload_dirs=[str(Path(__file__).parent)],
        )
    else:
        uvicorn.run(
            app,
            host=host,
            port=port,
            log_level="info",
            reload=False,
        )


if __name__ == "__main__":
    main()
